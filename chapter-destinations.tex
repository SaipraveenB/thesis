\chapter{Destination-passing}
\label{chapter-destinations}

The natural notion of ordering provided by ordered linear logic
is quite convenient for encoding transition systems that 
have a stack or tree-based control structure. The ordered
abstract machine SSOS specifications from Chapter~6 demonstrate
this; another example is the push-down automaton for parenthesis
matching discussed in the introduction, which we can now present,
in Figure~\ref{fig:pda-ord}, as an \sls~specification.

\begin{figure}[ht]
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/pda-ord.sls}
\caption{Ordered \sls~specification of a PDA for parenthesis matching.}
\label{fig:pda-ord}
\end{figure}

The natural expression of order provided by \sls~makes ordered
abstract machine specifications and the PDA specification in
Figure~\ref{fig:pda-ord} much more concise. However, in a way that we
will make precise in this chapter, ordered logic does not actually add
any more {\it expressiveness} to concurrent specifications relative to
linear logic. In Chapter~5, we argued that ordered abstract machines
were at least as expressive as (moded) natural semantics by giving a
transformation, operationalization, from the latter to the
former. Analogously, in this chapter we will argue that concurrent
specifications in linear logic are just as expressive as concurrent
specifications in ordered logic by giving a transformation, {\it
  destination-adding}, from the latter to the former.  As 
originally presented by Pfenning and I in \cite{simmons11logical}, 
the destination-adding transformation turns all ordered
atomic propositions into linear atomic propositions, but tagged them
with two new arguments (the destinations of the destination-adding
transformation) that serve as a link between the formerly-ordered
atomic proposition and the formerly-ordered atomic propositions that
were previously to their left and to their right. 

Destinations (terms of type ${\sf dest}$) have no constructors, they
are only introduced as variables by existential quantification.  When
we perform the destination-adding transformation on the PDA in
Figure~\ref{fig:pda-ord}, we get the PDA in Figure~\ref{fig:pda-lin}.


\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/pda-lin.sls}
\caption{Linear \sls~specification of a PDA for parenthesis matching.}
\label{fig:pda-lin}
\end{figure}

As an aside, the specification in Figure~\ref{fig:pda-lin}, like every
other specification that results from destination-adding, has no
occurrences of ${\downarrow}A^-$ and no ordered atomic propositions. By
the discussion in Section~\ref{sec:perm-fragments}, we would therefore
be justified in viewing this specification as a linear logical
specification (or a CLF specification) instead of a ordered logical
specification in \sls.  This would not impact the structure of the
derivations significantly; essentially, it just means that we would
write $A^+_1 \lolli \{ A^+_2 \}$ instead of $A^+_1 \lefti \{ A^+_2
\}$.  This reinterpretation was used in \cite{simmons11logical}, but
we will stick with the notation of ordered logic for consistency,
while recognizing that there is nothing ordered
about specifications like the one in Figure~\ref{fig:pda-lin}. 

When the destination-adding translation is applied to ordered abstract
machine SSOS specifications, the result is a style of SSOS
specification called {\it destination-passing}. Destination-passing
specifications were the original style of SSOS specification proposed
in the CLF tech reports~\cite{cervesato02concurrent}. Whereas the
operationalization transformation exposed the structure of natural
semantics proofs so that they could be modularly extended with
stateful features, the destination-adding translation exposes the
control structure of specifications, allowing the language to be
modularly extended with control effects and effects like
synchronization in concurrent specifications.

\section{Logical transformation: destination-adding}
\label{sec:destination-adding}

The destination-adding translation presented here is essentially the
same as the one presented and proved correct in
\cite{simmons11logical}. The translation in that paper operated over
rules of the form $\forall \overline{x}. S_1 \righti \{ S_2 \}$,
whereas ours will operate over rules of the form $\forall
\overline{x}. S_1 \lefti \{ S_2 \}$, but the difference between
$\righti$ and $\lefti$ is irrelevant for first-order
\sls~specifications.\footnote{The monad $\{ S_2 \}$ did not actually
  appear in \cite{simmons11logical}, and the presentation took
  polarity into account but was not explicitly polarized. We are
  justified in reading the lax modality back in by the sort of erasure
  argument discussed in Section~\ref{sec:perm-fragments}.} The syntactic
category $S$ is a refinement of the positive types $A^+$ defined by
the following grammar:
\[
S ::= p^+_\mpers \mid p^+_\meph \mid p^+ \mid \one
\mid t \doteq s \mid S_1 \fuse S_2 \mid \exists x{:}\tau. S
\]
The translation of a rule $\forall \overline{x}. S_1 \lefti \{ S_2 \}$
is then $\forall \overline{x}.\, \forall d_L{:}{\sf dest}.\, \forall
d_R{:}{\sf dest}.\, \llbracket S_1 \rrbracket^{d_L}_{d_R} \lefti \{
\llbracket S_2 \rrbracket^{d_L}_{d_R} \}$, where $\llbracket S
\rrbracket^{d_L}_{d_R}$ is defined in Figure~\ref{fig:destadd-pos}. It
is also necessary to transform all ordered predicates with kind
$\Pi. x_1{:}\tau_1\ldots \Pi.x_n{:}\tau_n.\,{\sf prop\,ord}$ that are
declared in the signature into predicates with kind
$\Pi. x_1{:}\tau_1\ldots \Pi.x_n{:}\tau_n.\, \Pi.d_L{:}{\sf dest}.\,
\Pi.d_R{:}{\sf dest}.\, {\sf prop\,ord}$ in order for the translation
of an ordered atomic proposition $p^+$ to remain a valid type in
the transformed signature.

\begin{figure}
\begin{align*}
\llbracket p^+ \rrbracket^{d_L}_{d_R} & := 
 {\sf a}\,t_1\ldots t_n\,d_L\,d_R ~~~ \mbox{(where $p^+ = {\sf a}\,t_1\ldots t_n$)}
\\
\llbracket p^+_\meph \rrbracket^{d_L}_{d_R} & := p^+_\meph \fuse d_L \doteq d_R
\\
\llbracket p^+_\mpers \rrbracket^{d_L}_{d_R} & := p^+_\mpers \fuse d_L \doteq d_R
\\
\llbracket \one \rrbracket^{d_L}_{d_R} & := d_L \doteq d_R
\\
\llbracket t \doteq s \rrbracket^{d_L}_{d_R} & := t \doteq s \fuse d_L \doteq d_R
\\
\llbracket S_1 \fuse S_2 \rrbracket^{d_L}_{d_R} & := 
 \exists d_M{:}{\sf dest}.\, 
   \llbracket S_1 \rrbracket^{d_L}_{d_M}
   \fuse
   \llbracket S_2 \rrbracket^{d_M}_{d_R}
\\
\llbracket \exists x{:}\tau.\,S \rrbracket^{d_L}_{d_R} & := 
 \exists x{:}\tau.\, \llbracket S \rrbracket^{d_L}_{d_R}
\end{align*}
\caption{Destination-adding transformation on positive propositions.}
\label{fig:destadd-pos}
\end{figure}

According to Figure~\ref{fig:destadd-pos}, the rule 
${\sf pop}$ in Figure~\ref{fig:pda-lin} should actually be written as
follows:
\begin{align*} 
  {\sf pop} & : 
  \forall x{:}{\sf tok}.\,
  \forall l{:}{\sf dest}.\,
  \forall r{:}{\sf dest}.\,
  \\
  & \qquad (\exists m_1{:}{\sf dest}.\, {\sf stack}\,x\,l\,m \fuse
   (\exists m_2{:}{\sf dest}.\, {\sf hd}\,m_1\,m_2 \fuse
     {\sf right}\,x\,m_2\,r))
  \\ 
  & \qquad\quad \lefti
  \{ 
    {\sf hd}\,l\,r
  \}
\end{align*}
The destination-adding transformation as
implemented\robnote{Implement, or don't say this; also discuss the
  implementation of the probably-correct transformation on
  higher-order specs if you get to that.} produces rules that are
equivalent to the specification in Figure~\ref{fig:destadd-pos}
but that avoid unnecessary equalities and push existential quantifiers
as far out as possible to get specifications that look more like
Figure~\ref{fig:pda-lin}. We write the result of the destination-adding
transformation on the signature $\Sigma$ as ${\it Dest}(\Sigma)$. 

We could consider another simplification: is it necessary to generate
a new destination $m$ by existential quantification in the head
$\exists m.\,{\sf stack}\,x\,l\,m \fuse {\sf hd}\,m\,r$ of ${\sf
  push}$ in Figure~\ref{fig:pda-lin}? There is already a destination
$m$ mentioned in the head that will be unused in the conclusion.  And
for the translation that takes all formerly-ordered atomic
propositions to linear atomic propositions, it would, in fact, be
possible to avoid generating new destinations in the transformation of
rules $\forall \overline{x}.\,S_1 \lefti \{ S_2 \}$ where the head
$S_2$ contains no more ordered atomic propositions than the premise
$S_1$. 

We preserve this quantifier in part because, as presented above, our
translation closely follows the contours of work by Morrill, Moot, and
Piazza on translating ordered logic into linear logic
\cite{morrill95higher,moot01linguistic}. That work is, in turn, based
on van Benthem's relational models of ordered logic, which closely
associate multiplicative conjunction $A \fuse B$ with existential
quantification \cite{vanbenthem91relational}. In some ways, the
aforementioned translations are more general than our
destination-adding transformation, as they handle a uniform logic
instead of the concurrent fragment presented here and in here
\cite{simmons11logical}. On the other hand, those translations only
operate on a propositional fragment without the unit of multiplicative
conjunction $\one$; as discussed in \cite[p.~57]{simmons11logical},
the addition non-ordered atomic propositions, $\one$, and $t \doteq s$
complicates matters significantly. 

In addition to following van Bentham's relational models, the
transformation as we have given it simplifies the correctness
proof (Theorem~\ref{thm:destcorrect}). The additional existential
quantifiers give us more structure to work with when considering
program abstraction in Chapter 8, and the result of applying the
transformation to ordered abstract machines is more in line with 
existing destination-passing SSOS specifications.

% Another reason for preserving the existential quantifier in the head
% of the ${\sf push}$ rule is that it allows us to make an extension to
% the destination-adding transformation beyond what was considered in
% \cite{simmons11logical}. As long as the head of every translated rule
% contains at least one formerly-ordered atomic proposition that has
% been turned into a linear atomic propsition, it is possible to 
% without breaking Theorem~\ref{thm:destcorrect}. 

%  The correctness of the transformation 
% depends critically on the fact that every portion of the context
% that might be used to successfully right focus on a translated positive 
% proposition $\llbracket S \rrbracket^{d_L}_{d_R}$ is a 

To prove the correctness of destination-adding, we must describe a 
translation $\llbracket \Psi; \Delta \rrbracket$ from process states
with ordered, linear, and persistent atomic propositions to ones
with only linear and persistent atomic propositions:
\begin{align*}
\llbracket \Psi; \cdot \rrbracket & = (\Psi, d_L{:}{\sf dest}; \cdot) 
\\
\llbracket \Psi; \Delta, x{:}\susp{{\sf a}\,t_1\ldots t_n} \rrbracket 
& = (\Psi', d_L{:}{\sf dest}, d_R{:}{\sf dest}; 
     \Delta', x{:}\susp{{\sf a}\,t_1\ldots t_n\,d_L\,d_R})\\
& \qquad
  \mbox{(where $\sf a$ is ordered and
  $\llbracket \Psi; \Delta \rrbracket = (\Psi', d_L{:}{\sf dest}; \Delta') $)}
\\
\llbracket \Psi; \Delta, x{:}\susp{p^+_\meph} \rrbracket 
& = (\Psi'; \Delta', x{:}\susp{p^+\meph})
 \qquad \mbox{(where
       $\llbracket \Psi; \Delta \rrbracket = (\Psi'; \Delta') $)}
\\
\llbracket \Psi; \Delta, x{:}\susp{p^+_\mpers} \rrbracket 
& = (\Psi'; \Delta', x{:}\susp{p^+\mpers})
  \qquad \mbox{(where 
       $\llbracket \Psi; \Delta \rrbracket = (\Psi'; \Delta') $)}
\end{align*}

\begin{theorem}[Correctness of destination-adding]~\\\label{thm:destcorrect}
$\llbracket \Psi; \Delta \rrbracket \leadsto_{{\it Dest}(\Sigma)}
 (\Psi_l; \Delta_l)$ if and only if 
$(\Psi; \Delta) \leadsto_\Sigma (\Psi_o; \Delta_o)$ and
$(\Psi_l; \Delta_l) = \llbracket \Psi_o, \Psi''; \Delta_o \rrbracket$ 
for some variable 
context $\Psi''$ containing destinations free in the first translated
context but not the second.
\end{theorem}

\begin{proof}
As in \cite[Theorem 2]{simmons11logical}.\robnote{Double check how the 
variable slack works.}
\end{proof}


If we leave off explicitly mentioning the variable context $\Psi$, 
then the trace that represents successfully processing 
the string {\sf [ ( ) ] }
with the transformed push-down automaton 
specification in Figure~\ref{fig:pda-lin} 
is as follows (we again underline ${\sf hd}$
for emphasis):
\begin{align*}
           & y_0{:}\susp{\underline{\sf hd}\,d_0\,d_1},
             x_1{:}\susp{{\sf left}\,{\sf sq}\,d_1\,d_2},
             x_2{:}\susp{{\sf left}\,{\sf pa}\,d_2\,d_3},
             x_3{:}\susp{{\sf right}\,{\sf pa}\,d_3\,d_4},
             x_4{:}\susp{{\sf right}\,{\sf sq}\,d_4\,d_5}
\\
\leadsto ~ & z_1{:}\susp{{\sf stack}\,{\sf sq}\,d_0\,d_6},
             y_1{:}\susp{\underline{\sf hd}\,d_6\,d_2}
             x_2{:}\susp{{\sf left}\,{\sf pa}\,d_2\,d_3},
             x_3{:}\susp{{\sf right}\,{\sf pa}\,d_3\,d_4},
             x_4{:}\susp{{\sf right}\,{\sf sq}\,d_4\,d_5}
\\
\leadsto ~ & z_1{:}\susp{{\sf stack}\,{\sf sq}\,d_0\,d_6},
             z_2{:}\susp{{\sf stack}\,{\sf pa}\,d_6\,d_7},
             y_2{:}\susp{\underline{\sf hd}\,d_7\,d_3}
             x_3{:}\susp{{\sf right}\,{\sf pa}\,d_3\,d_4},
             x_4{:}\susp{{\sf right}\,{\sf sq}\,d_4\,d_5}
\\
\leadsto ~ & z_1{:}\susp{{\sf stack}\,{\sf sq}\,d_0\,d_6},
             y_3{:}\susp{\underline{\sf hd}\,d_6\,d_4}
             x_4{:}\susp{{\sf right}\,{\sf sq}\,d_4\,d_5}
\\
\leadsto ~ & y_4{:}\susp{\underline{\sf hd}\,d_0\,d_5}
\end{align*}


\begin{figure}[t]
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-vestige.sls}
\caption{Translation of Figure~\ref{fig:cbv-ev-ssos-fun} with vestigial destinations.}
\label{fig:dest-vestige}
\end{figure}

\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-cbv.sls}
\caption{Translation of Figure~\ref{fig:cbv-ev-ssos-fun} without vestigial destinations.}
\label{fig:dest-cbv}
\end{figure}



\subsection{Vestigial destinations}

When we apply the translation of expressions to the call-by-value
lambda calculus specification from Figure~\ref{fig:cbv-ev-ssos-fun},
we get the specification in Figure~\ref{fig:dest-vestige}, which is
has one problem: the second argument to ${\sf eval}$ and ${\sf retn}$
is always $d'$, and the destination never changes; it is essentially a
vestige of the destination-adding transformation. As long as we are
transforming a sequential ordered abstract machine, we can eliminate
this vestigial destination, giving us the specification in
Figure~\ref{fig:dest-cbv}. This extra destination is {\it not}
vestigial when we translate a parallel specification, but as we
discuss in Section~\ref{sec:modular-parallelism}, we don't necessarily
want to run destination-adding on parallel ordered abstract machines
anyway.

\subsection{Persistent destination passing}

When we translate our PDA specification, it is actually not necessary
to translate ${\sf hd}$, ${\sf left}$, ${\sf right}$ and ${\sf stack}$ into
linear atomic propositions; if we translate ${\sf hd}$ as
a linear predicate but translate the other predicates as persistent
predicates, it will still be the case that there is always exactly one
linear atomic proposition ${\sf hd}\,d_L\,d_R$ in the context, at most one
${\sf stack}\,x\,d\,d_L$ proposition with the same destination $d_L$, 
and at most one ${\sf right}\,x\,d_R\,d$ or ${\sf left}\,x\,d_R\,d$ 
with the same destination $d_R$. This means it is still the case that the
PDA accepts the string if and only if there is the following series of 
transitions:
\begin{align*}
 %(d_0{:}{\sf dest}, \ldots, d_{n+1}{:}{\sf dest}; 
(    x{:}\susp{{\sf hd}\,d_0\,d_1}, 
    y_1{:}\susp{{\sf left}\,x_1\,d_1\,d_2},
    \ldots&,
    y_n{:}\susp{{\sf right}\,x_n\,d_n\,d_{n+1}})% )
%\\
% &
~~ \leadsto^* ~~
%   (\Psi; 
(\Gamma, z{:}\susp{{\sf hd}\,d_0\,d_{n+1}})%)
\end{align*}
Unlike the entirely-linear PDA specification, the final state may include
some additional 
persistent propositions, represented by $\Gamma$. Specifically, the final state
contains all the original ${\sf left}\,x\,d_i\,d_{i+1}$ and
${\sf right}\,x\,d_i\,d_{i+1}$ propositions 
along with all the ${\sf stack}\,x\,d\,d'$ propositions that were created
during the course of evaluation.

% \begin{figure}[t]
% \fvset{fontsize=\small,boxwidth=229pt}
% \VerbatimInput{sls/pda-pers.sls}
% \caption{Linear/persistent \sls~specification of a PDA for parenthesis
%   matching.}
% \label{fig:pda-pers}
% \end{figure}

I originally conjectured that a version of
Theorem~\ref{thm:destcorrect} would hold in any specification that
turned some ordered atomic propositions linear and others
persistent just as long as at least one atomic proposition in
the premise of every rule remained linear after transformation.  
This would have given a
generic justification for turning ${\sf left}$, ${\sf right}$ and ${\sf
  stack}$ persistent in Figure~\ref{fig:pda-lin} and to turning ${\sf
  cont}$ persistent in Figure~\ref{fig:dest-cbv}. However, that
condition is not strong enough.  To see why, consider a signature with
one rule, ${\sf a} \fuse {\sf b} \fuse {\sf a} \lefti \{ {\sf b} \}$,
where ${\sf a}$ and ${\sf b}$ are ordered atomic propositions.  We can
construct the following trace:
\begin{align*}
& (x_1{:}\susp{\sf a}, x_2{:}\susp{\sf b}, x_3{:}\susp{\sf a}, 
  x_4{:}\susp{\sf b}, x_5{:}\susp{\sf a})
\leadsto 
(x{:}\susp{\sf b},
  x_4{:}\susp{\sf b}, x_5{:}\susp{\sf a})
\not\leadsto  
\intertext{From the same starting point, exactly one
other trace is possible:}
& (x_1{:}\susp{\sf a}, x_2{:}\susp{\sf b}, x_3{:}\susp{\sf a}, 
  x_4{:}\susp{\sf b}, x_5{:}\susp{\sf a})
\leadsto 
(x_1{:}\susp{\sf a}, x_2{:}\susp{\sf b}, x{:}\susp{\sf b})
\not\leadsto 
\end{align*}
However, if we perform the destination-passing transformation, letting
${\sf a}\,d\,d'$ be a persistent atomic proposition and letting ${\sf
  b}\,d\,d'$ be a linear atomic proposition, then we have a series of
transitions in the transformed specification that can reuse the atomic
proposition ${\sf a}\,d_2\,d_3$ in a way that doesn't correspond to
any series of transitions in ordered logic:
\begin{align*}
&  x_1{:}\susp{{\sf a}\,d_0\,d_1}, 
   x_2{:}\susp{{\sf b}\,d_1\,d_2}, 
   x_3{:}\susp{{\sf a}\,d_2\,d_3}, 
   x_4{:}\susp{{\sf b}\,d_3\,d_4}, 
   x_5{:}\susp{{\sf a}\,d_4\,d_5}
\\ \leadsto~
&  x_1{:}\susp{{\sf a}\,d_0\,d_1}, 
   \underline{x{:}\susp{{\sf b}\,d_0\,d_3}}, 
   x_3{:}\susp{{\sf a}\,d_2\,d_3}, 
   x_4{:}\susp{{\sf b}\,d_3\,d_4}, 
   x_5{:}\susp{{\sf a}\,d_4\,d_5}
\\ \leadsto~
&  x_1{:}\susp{{\sf a}\,d_0\,d_1}, 
   x{:}\susp{{\sf b}\,d_0\,d_3}, 
   x_3{:}\susp{{\sf a}\,d_2\,d_3}, 
   \underline{x'{:}\susp{{\sf b}\,d_2\,d_5}}, 
   x_5{:}\susp{{\sf a}\,d_4\,d_5}
\end{align*}
In the
first process state, there is a path $d_0, d_1, d_2, d_3, d_4, d_5$ through
the context that reconstructs the ordering in the original ordered context.
In the second process state, there is still a path $d_0, d_3, d_4, d_5$ that
allows us to reconstruct the ordered context
$(x{:}\susp{\sf b},
  x_4{:}\susp{\sf b}, x_5{:}\susp{\sf a})$ by ignoring the persistent
propositions associated with $x_1$ and $x_3$. 
However, in the third process state above, no path exists, so the final
state cannot be reconstructed as any ordered context. 

It would be good to identify a condition that allowed us to
selectively turn some ordered propositions persistent when
destination-adding without violating (a version of)
Theorem~\ref{thm:destcorrect}. In the absence of such a generic
condition, it is still straightforward to see that performing
destination-passing and then turning some propositions persistent is
an {\it abstraction}: if the original system can make a series of
transitions, the transformed system can simulate those transitions,
but the reverse may not be true. Furthermore, for systems we are
interested in (like push-down automata with persistent ${\sf stack}$,
${\sf left}$, and ${\sf right}$ or the sequential ordered abstract
machines with persistent ${\sf cont}$), it happens to be the case that
the abstraction is precise: the destination-passing specification can
only make transitions which were possible in the ordered
specification.

\section{Exploring the richer fragment}

In \cite{simmons11logical}, we were interested in exact logical
correspondence between ordered abstract machine SSOS specifications
and destination-passing SSOS specifications. Destination-adding was
useful in that setting because it exposes information about the
control structure of computations; this control structure can be
harnessed by the program abstraction methodology described in the next
chapter to derive program analyses. In keeping with our broader use of
the logical correspondence, in this section we will discuss
programming language features that are not easily expressible with
ordered abstract machine SSOS specifications but that can be easily
expressed with destination-passing SSOS specifications. Consequently,
these are features that can be modularly added to (sequential) ordered
abstract machine specifications that have undergone the
destination-adding transformation.

The semantics of parallelism and failure presented in
Section~\ref{sec:modular-parallelism} are new. The semantics of
futures (Section~\ref{sec:dest-futures}) and synchronization
(Section~\ref{sec:dest-synch}) are a based on the specifications first
presented in the CLF tech report \cite{cervesato02concurrent}; the
semantics of first-class continuations
(Section~\ref{sec:dest-continuations}) were presented previously in
\cite{pfenning04substructural,pfenning09substructural}. In
destination-passing semantics, when we are dealing with fine-grained
issues of control flow, the interaction of programming language
features becomes more delicate.  Parallel evaluation, recoverable
failure, and synchronization are compatible features, as are
synchronization and futures. Failure and first-class continuations are
also compatible. We will not handle other interactions, though it
would be interesting to explore the adaptation of Moreau and Ribbens'
abstract machine for Scheme with parallel evaluation and ${\sf
  callcc}$ as a substructural operational semantics
\cite{moreau96semantics}

\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-pair.sls}
\caption{Destination-passing semantics for parallel evaluation of pairs.}
\label{fig:dest-pair}
\end{figure}

\subsection{Alternate semantics for parallelism and exceptions}
\label{sec:modular-parallelism}

In Section~\ref{sec:failure}, we discussed how parallel evaluation and
recoverable failure can be combined in an ordered abstract machine
SSOS specification. Due to the fact that the two parts of a parallel
ordered abstract machine are separated by an arbitrary amount of
ordered context, some potentially desirable semantics ways of
integrating parallelism and failure were difficult or impossible to
express, however. 

Once we transition to destination-passing SSOS specifications, it is
possible to give a more direct semantics to parallel evaluation that
better facilitates talking about failure. Instead of having the stack
frame associated with parallel pairs be ${\sf cont}\,{\sf pair1}$ (as
in Figure~\ref{fig:ssos-minml-core}) or ${\sf cont2}\,{\sf pair1}$ (as
discussed in Section~\ref{sec:failure}), we create a continuation
${\sf cont2}\,{\sf pair1}\,d_1\,d_2\,d$ with {\it three} destinations;
$d_1$ and $d_2$ represent the return destinations points of the two
subcomputations, whereas $d$ represents the destination to which the
evaluated pair is to be returned. This strategy applied to the
parallel evaluation of pairs is shown in Figure~\ref{fig:dest-pair}.

In ordered specifications, an ordered atomic proposition can be
directly connected to at most two other ordered propositions: the
proposition immediately to the left in the ordered context, and the
proposition immediately to the right in the ordered context. What
Figure~\ref{fig:dest-pair} demonstrates is that, with destinations, a
linear proposition can be locally connected to {\it any finite number}
of other propositions. Whereas in ordered abstract machine
specifications the parallel structure of a computation had to be
reconstructed by parsing the context in postfix, a linear
destination-passing specification uses destinations to thread together
the treelike dependencies in the context. It would presumably be
possible to consider a different version of the parallel
operationalization that targeted this form of destination-passing
specification specifically, but we will not consider such a
transformation in this thesis. 

\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-fail-paror.sls}
\caption{Integration of parallelism and exceptions; signals failure as
  soon as possible.}
\label{fig:dest-fail-paror}
\end{figure}

By the destination-based parallel continuations, we give, in
Figure~\ref{fig:dest-fail-paror}, a semantics for recoverable failure
that eagerly returns errors from either branch of a parallel
computation. The rules ${\sf ev/errorL}$ and ${\sf ev/errorR}$ pass on
errors returned to a place where the computation forks.  Those two
rules also leave behind a linear proposition ${\sf terminate}\,d$ that
will abort the other branch of computation if it returns successfully
(rule ${\sf term/retn}$) or with an error (rule ${\sf term/err}$). It
would also be possible to add additional rules like ${\sf cont}\,d'\,d
\fuse {\sf terminate}\,d \lefti \{ {\sf terminate}\,d' \}$ that
actively aborted the useless branch instead of passively waiting for
it to finish.

\subsection{Synchronization}
\label{sec:dest-synch}

The CLF tech report gives a presentation of the full set of Concurrent
ML primitives that is equally applicable to destination-passing
\sls~specifications \cite{cervesato02concurrent}. Rather than
reprising that specification, we will discuss an extremely simple form
of synchronous communication in Figure~\ref{fig:dest-synch}. 

\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-synch.sls}
\caption{Simple synchronization.}
\label{fig:dest-synch}
\end{figure}

New channels are created by the evaluating $\interp{{\sf chan}\,c.e} =
{\sf chan}\,\lambda x.\,\interp{e}$, which introduces a new channel
(an LF term of the type ${\sf channel}$ that has no constructors and
substituted it for the bound $c$ in $e$). Synchronization happens when
there is both a send ${\sf send}\,c\,e$ in one computation and a
receive ${\sf recv}\,c$ in a different computation along the same
channel. The expression $e$ will evaluate to a value $v$ in the first
computation (rule ${\sf ev/send}$). The inter-process communication is
driven by rule ${\sf ev/send1}$, which allows computation to continue
in both the sender and the receiver.

Synchronous communication introduces the possibility of
deadlocks. Without synchronous communication, a suspended atomic
proposition ${\sf eval}\,e\,d$ can always cause a transition to
happen, and the combination of a proposition ${\sf retn}\,v\,d$ and a
continuation ${\sf cont}\,f\,d\,d'$ can either immediately transition
or else are permanently in a stuck
state. In~\cite{pfenning09substructural}, this observation motivated a
classification of atomic propositions as {\it active} propositions
like ${\sf eval}\,e\,d$ that independently drive computation, {\it
  passive} propositions like ${\sf cont}\,f\,d'\,d$ that do not drive
computation, and {\it latent} propositions like ${\sf retn}\,f\,d$
that may or may not drive computation based on the ambient environment
of passive propositions. The specification in
Figure~\ref{fig:dest-synch} does not respect this classification
because ${\sf eval}\,({\sf recv}\,c)\,d$ cannot immediately
transition. We could restore this classification by having a rule
${\sf eval}\,({\sf recv}\,c)\,d \lefti \{ {\sf await}\,c\,d \}$ for
some new passive linear predicate ${\sf await}$ and then replacing the
premise ${\sf eval}\,({\sf recv}\,c)\,d$ in ${\sf ev/send1}$ with
${\sf await}\,c\,d$.

\subsubsection{Labeled transitions}

Substructural operational semantics are a very continuation-focused
formalism, and continuations are not always the most natural way to
express a specification. This observation motivated our
operationalization transformation from natural semantics and our
informal discussion of statefully-modular natural semantics in
Section~\ref{sec:enriching-natsem}. 

In Chapter~6, we showed that the continuation-focused perspective of
SSOS allowed us to expose computation to the ambient state. With the
example of synchronization above, we see that destination-passing SSOS
specifications also expose computations in the process state to {\it
  other computations}, which is what allows the synchronization in
rule ${\sf ev/send1}$ to take place. In small-step operational
semantics, labeled deduction is used to describe specifications like
the one above:
\begin{itemize}
\item $e ~{\stackrel{\footnotesize{c{\textbf{!}}v}}{\longmapsto}}~
e'$ if $e$ steps to $e'$ by reducing some subterm ${\sf send}\,c\,v$,
to $\interp{\langle\rangle} = {\sf unit}$,
\item $e
~{\stackrel{\footnotesize{c{\textbf{?}}v}}{\longmapsto}}~ e'$ if $e$
steps to $e'$ by reducing some subterm ${\sf recv}\,c$ to $v$, and 
\item $e_1$ in parallel with $e_2$ can reduce to $e_1'$
in parallel with $e_2'$ if $e_1
~{\stackrel{\footnotesize{c{\textbf{!}}v}}{\longmapsto}}~ e_1'$ and
$e_2 ~{\stackrel{\footnotesize{c{\textbf{?}}v}}{\longmapsto}}~ e_2'$.
\end{itemize}
Labels essentially serve to pass messages up through the inductive
structure of a proposition.  In destination-passing SSOS semantics, on
the other hand, the internal structure of $e$ is spread out as a
series of continuation frames throughout the context, and so the
innermost redexes of terms can be directly connected. It would be
interesting (but probably quite nontrivial) to consider a translation
from labeled deduction systems to destination-passing SSOS
specifications for synchronization along the lines of the
operationalization transformation.


\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-futures.sls}
\caption{Call-by-future.}
\label{fig:dest-futures}
\end{figure}

\subsection{Futures}
\label{sec:dest-futures}

Futures can be seen as a parallel version of call-by-value, and the
presentation in Figure~\ref{fig:dest-futures} can be compared to the
environment semantics for call-by-value in
Figure~\ref{fig:ssos-by-env}. We introduce future-functions as a new
kind of function ${\sf flam}\,\lambda x.e$ comparable to plain-vanilla
call-by-value functions ${\sf lam}\,\lambda x.e$, lazy call-by-need
functions ${\sf lazylam}\,\lambda x.e$, and environment-semantics
functions ${\sf envlam}\,\lambda x.e$. As in the environment semantics
specification, when a call-by-future function returns to a frame
$\interp{\Box\,e_2} = {\sf app1}\,e_2$, we create a new expression $x$
by existential quantification. However, instead of suspending the
function body on the stack as we did in Figure~\ref{fig:ssos-by-env},
in Figure~\ref{fig:dest-futures} we create a new destination ${\it
  dfuture}$ and start evaluating the function argument towards that
destination (rule ${\sf ev/fapp1}$). We also create a linear
proposition -- ${\sf promise}\,{\it dfuture}\,x$ -- that will take
any value returned to ${\it dfuture}$ and permanently bind it to $x$
(rule ${\sf ev/promise}$). As a proposition that only exists during
the course of evaluating the argument, ${\sf promise}$ is analogous to
the ${\sf blackhole}$ predicate form the call-by-need specification.

Futures illustrate the use of destination-passing to create new and
potentially disconnected threads of computation. This was not possible
in the ordered framework where every computation had to be somewhere
specific in the ordered context relative to the current computation --
either to the left, or to the right. The destination-passing semantics
of continuations interact seamlessly with the semantics of
synchronization and parallelism, but not with the semantics of
recoverable failure: we would have to make some choice about what to 
do when a future signals failure.

\subsection{First-class continuations}
\label{sec:dest-continuations}

The interaction of parallel evaluation and first-class continuations
has been evaluated by Moreau and Ribbens in the context of Scheme
\cite{moreau96semantics}

; giving an SSOS encoding of their abstract
machine would be interesting, but we do not do so here.

