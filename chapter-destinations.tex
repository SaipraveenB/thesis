\chapter{Destination-passing}
\label{chapter-destinations}

The natural notion of ordering provided by ordered linear logic is
quite convenient for encoding transition systems that maintain a stack
or tree-based control structure. The ordered abstract machine SSOS
specifications from Chapter~6 demonstrate this; another example is the
push-down automaton for generic bracket matching discussed in the
introduction, which we can now present, in Figure~\ref{fig:pda-ord},
as an \sls~specification.

\begin{figure}[ht]
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/pda-ord.sls}
\caption{Ordered \sls~specification of a PDA for parenthesis matching}
\label{fig:pda-ord}
\end{figure}

Ordered atomic propositions in \sls~can make concurrent specifications
more concise than comparable CLF specifications. However, in a way
that we will make precise in this chapter, ordered logic does not
actually add any {\it expressiveness} to concurrent specifications
relative to linear logic. In Chapter~5, we argued that ordered
abstract machines were at least as expressive as (moded) natural
semantics by giving a transformation, operationalization, from the
latter to the former. Analogously, in this chapter we will argue that
concurrent specifications in linear logic are just as expressive as
concurrent specifications in ordered logic by giving a transformation,
{\it destination-adding}, from the latter to the former. This
destination-adding transformation, which we originally presented in
\cite{simmons11logical}, turns all ordered atomic propositions into
linear atomic propositions, and tags them with two new arguments (the
destinations of the destination-adding transformation). These extra
destinations serve as a link between a formerly-ordered atomic
proposition and its two former neighbors in the ordered context.

Destinations (terms of type ${\sf dest}$) have no constructors: they
are only introduced as variables by existential quantification, which
means they can freely be subject to unification when the conclusion of
a rule declares them to be equal (as described in
Section~\ref{sec:slsframework}).  When we perform the
destination-adding transformation on the specification in
Figure~\ref{fig:pda-ord}, we get the specification in
Figure~\ref{fig:pda-lin}. 

\begin{figure}[ht]
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/pda-lin.sls}
\caption{Linear \sls~specification of a PDA for parenthesis matching}
\label{fig:pda-lin}
\end{figure}

The specification in Figure~\ref{fig:pda-lin}, like every other
specification that results from destination-adding, has no occurrences
of ${\downarrow}A^-$ and no ordered atomic propositions.  As a result,
we write \verb|hd L M| instead of \verb|$hd L M|, omitting the
optional linearity indicator \verb|$| on the linear atomic
propositions as discussed in
Section~\ref{sec:prototype}. Additionally, by the discussion in
Section~\ref{sec:perm-fragments}, we would be justified in viewing
this specification as a linear logical specification (or a CLF
specification) instead of a ordered logical specification in \sls.
This would not impact the structure of the derivations significantly;
essentially, it just means that we would write $A^+_1 \lolli \{ A^+_2
\}$ instead of $A^+_1 \lefti \{ A^+_2 \}$.  This reinterpretation was
used in \cite{simmons11logical}, but we will stick with the notation
of ordered logic for consistency, while recognizing that there is
nothing ordered about specifications like the one in
Figure~\ref{fig:pda-lin}.

When the destination-adding translation is applied to ordered abstract
machine SSOS specifications, the result is a style of SSOS
specification called {\it destination-passing}. Destination-passing
specifications were the original style of SSOS specification proposed
in the CLF tech reports~\cite{cervesato02concurrent}. Whereas the
operationalization transformation exposed the structure of natural
semantics proofs so that they could be modularly extended with
stateful features, the destination-adding translation exposes the
control structure of specifications, allowing the language to be
modularly extended with control effects and effects like
synchronization in concurrent specifications.

\section{Logical transformation: destination-adding}
\label{sec:destination-adding}

The destination-adding translation presented here is essentially the
same as the one presented in \cite{simmons11logical}. The translation
in that paper operated over rules of the form $\forall
\overline{x}. S_1 \righti \{ S_2 \}$, whereas ours will operate over
rules of the form $\forall \overline{x}. S_1 \lefti \{ S_2 \}$, but
the difference between $\righti$ and $\lefti$ is irrelevant for
first-order \sls~specifications.\footnote{The monad $\{ S_2 \}$ did
  not actually appear in \cite{simmons11logical}, and the presentation
  took polarity into account but was not explicitly polarized. We are
  justified in reading the lax modality back in by the erasure
  arguments discussed in Section~\ref{sec:perm-fragments}.} The
syntactic category $S$ is a refinement of the positive types $A^+$
defined by the following grammar:
\[
S ::= p^+_\mpers \mid p^+_\meph \mid p^+ \mid \one
\mid \lf{t} \doteq \lf{s} \mid S_1 \fuse S_2 \mid \exists \lf{x}{:}\tau. S
\]
The translation of a rule $\forall \lf{\overline{x}}. S_1 \lefti \{ S_2 \}$
is then $\forall \lf{\overline{x}}.\, \forall \lf{d_L}{:}{\sf dest}.\, \forall
\lf{d_R}{:}{\sf dest}.\, \llbracket S_1 \rrbracket^{\lf{d_L}}_{\lf{d_R}} \lefti \{
\llbracket S_2 \rrbracket^{\lf{d_L}}_{\lf{d_R}} \}$, where $\llbracket S
\rrbracket^{\lf{d_L}}_{\lf{d_R}}$ is defined in Figure~\ref{fig:destadd-pos}. It
is also necessary to transform all ordered predicates with kind
$\Pi. \lf{x_1}{:}\tau_1\ldots \Pi.\lf{x_n{}:}\tau_n.\,{\sf prop\,ord}$ that are
declared in the signature into predicates with kind
$\Pi. \lf{x_1}{:}\tau_1\ldots \Pi.\lf{x_n}{:}\tau_n.\, {\sf dest} \rightarrow
{\sf dest} \rightarrow {\sf prop\,ord}$ in order for the translation
of an ordered atomic proposition $p^+$ to remain a valid type in
the transformed signature.

\begin{figure}
\begin{align*}
\llbracket p^+ \rrbracket^{\lf{d_L}}_{\lf{d_R}} & = 
 {\sf a}\,\lf{t_1}\ldots \lf{t_n}\,\lf{d_L}\,\lf{d_R} ~~~ \mbox{(where $p^+ = {\sf a}\,\lf{t_1}\ldots \lf{t_n}$)}
\\
\llbracket p^+_\meph \rrbracket^{\lf{d_L}}_{\lf{d_R}} & = p^+_\meph \fuse \lf{d_L} \doteq \lf{d_R}
\\
\llbracket p^+_\mpers \rrbracket^{\lf{d_L}}_{\lf{d_R}} & = p^+_\mpers \fuse \lf{d_L} \doteq \lf{d_R}
\\
\llbracket \one \rrbracket^{\lf{d_L}}_{\lf{d_R}} & = \lf{d_L \doteq d_R}
\\
\llbracket t \doteq s \rrbracket^{\lf{d_L}}_{\lf{d_R}} & = \lf{t} \doteq \lf{s} \fuse \lf{d_L} \doteq \lf{d_R}
\\
\llbracket S_1 \fuse S_2 \rrbracket^{\lf{d_L}}_{\lf{d_R}} & = 
 \exists \lf{d_M}{:}{\sf dest}.\, 
   \llbracket S_1 \rrbracket^{\lf{d_L}}_{\lf{d_M}}
   \fuse
   \llbracket S_2 \rrbracket^{\lf{d_M}}_{\lf{d_R}}
\\
\llbracket \exists \lf{x}{:}\tau.\,S \rrbracket^{\lf{d_L}}_{\lf{d_R}} & := 
 \exists \lf{x}{:}\tau.\, \llbracket S \rrbracket^{\lf{d_L}}_{\lf{d_R}}
\end{align*}
\caption{Destination-adding transformation}
\label{fig:destadd-pos}
\end{figure}

According to Figure~\ref{fig:destadd-pos}, the rule 
${\sf pop}$ in Figure~\ref{fig:pda-lin} should actually be written as
follows:
\begin{align*} 
  {\sf pop} & : 
  \forall \lf x{:}{\sf tok}.\,
  \forall \lf l{:}{\sf dest}.\,
  \forall \lf r{:}{\sf dest}.\,
  \\
  & \qquad (\exists \lf{m_1}{:}{\sf dest}.\, {\sf stack}\,\lf{x}\,\lf{l}\,\lf{m} \fuse
   (\exists \lf{m_2}{:}{\sf dest}.\, {\sf hd}\,\lf{m_1}\,\lf{m_2} \fuse
     {\sf right}\,\lf{x}\,\lf{m_2}\,\lf{r}))
  \\ 
  & \qquad\quad \lefti
  \{ 
    {\sf hd}\,\lf{l}\,\lf{r}
  \}
\end{align*}
The destination-adding transformation as
implemented\robnote{Implement, or don't say this; also discuss the
  implementation of the probably-correct transformation on
  higher-order specs if you get to that.} produces rules that are
equivalent to the specification in Figure~\ref{fig:destadd-pos}
but that avoid unnecessary equalities and push existential quantifiers
as far out as possible to get specifications that look more like
Figure~\ref{fig:pda-lin}. We write the result of the destination-adding
transformation on the signature $\Sigma$ as ${\it Dest}(\Sigma)$. 

We can consider a further simplification: is it necessary to generate
a new destination $\lf{m}$ by existential quantification in the head
$\exists \lf{m}.\,{\sf stack}\,\lf{x}\,\lf{l}\,\lf{m} \fuse {\sf hd}\,\lf{m}\,\lf{r}$ of ${\sf
  push}$ in Figure~\ref{fig:pda-lin}? There is already a destination
$\lf m$ mentioned in the head that will be unused in the conclusion.  It
would, in fact, be possible to avoid generating new destinations in
the transformation of rules $\forall \lf{\overline{x}}.\,S_1 \lefti \{ S_2
\}$ where the head $S_2$ contains no more ordered atomic propositions
than the premise $S_1$. 

We don't perform this simplification for a number of reasons. First
and foremost, the transformation described in
Figure~\ref{fig:destadd-pos} more closely follows the previous work by
Morrill, Moot, Piazza, and van Benthem discussed in
Section~\ref{sec:correspondence-related}, and transformation as given
simplifies the correctness proof (Theorem~\ref{thm:destcorrect}).
Pragmatically, the additional existential quantifiers also give us
more structure to work with when considering program abstraction in
Chapter 8. Finally, if we apply both the transformation in
Figure~\ref{fig:destadd-pos} and a transformation that reuses
destinations to an ordered abstract machine SSOS specification, the
former transformation produces results that are more in line with
existing destination-passing SSOS specifications.

% Another reason for preserving the existential quantifier in the head
% of the ${\sf push}$ rule is that it allows us to make an extension to
% the destination-adding transformation beyond what was considered in
% \cite{simmons11logical}. As long as the head of every translated rule
% contains at least one formerly-ordered atomic proposition that has
% been turned into a linear atomic propsition, it is possible to 
% without breaking Theorem~\ref{thm:destcorrect}. 

%  The correctness of the transformation 
% depends critically on the fact that every portion of the context
% that might be used to successfully right focus on a translated positive 
% proposition $\llbracket S \rrbracket^{\lf{d_L}}_{\lf{d_R}}$ is a 

To prove the correctness of destination-adding, we must describe a 
translation $\llbracket \Psi; \Delta \rrbracket$ from process states
with ordered, linear, and persistent atomic propositions to ones
with only linear and persistent atomic propositions:
\begin{align*}
\llbracket \Psi; \cdot \rrbracket & = (\Psi, \lf{d_L}{:}{\sf dest}; \cdot) 
\\
\llbracket \Psi; \Delta, x{:}\susp{{\sf a}\,\lf{t_1}\ldots \lf{t_n}} \rrbracket 
& = (\Psi', \lf{d_L}{:}{\sf dest}, \lf{d_R}{:}{\sf dest}; 
     \Delta', x{:}\susp{{\sf a}\,\lf{t_1}\ldots \lf{t_n}\,\lf{d_L}\,\lf{d_R}})\\
& \qquad
  \mbox{(where $\sf a$ is ordered and
  $\llbracket \Psi; \Delta \rrbracket = (\Psi', \lf{d_L}{:}{\sf dest}; \Delta') $)}
\\
\llbracket \Psi; \Delta, x{:}\susp{p^+_\meph} \rrbracket 
& = (\Psi'; \Delta', x{:}\susp{p^+_\meph})
 \qquad \mbox{(where
       $\llbracket \Psi; \Delta \rrbracket = (\Psi'; \Delta') $)}
\\
\llbracket \Psi; \Delta, x{:}\susp{p^+_\mpers} \rrbracket 
& = (\Psi'; \Delta', x{:}\susp{p^+_\mpers})
  \qquad \mbox{(where 
       $\llbracket \Psi; \Delta \rrbracket = (\Psi'; \Delta') $)}
\end{align*}

\begin{theorem}[Correctness of destination-adding]~\\\label{thm:destcorrect}
$\llbracket \Psi; \Delta \rrbracket \leadsto_{{\it Dest}(\Sigma)}
 (\Psi_l; \Delta_l)$ if and only if 
$(\Psi; \Delta) \leadsto_\Sigma (\Psi_o; \Delta_o)$ and
$(\Psi_l; \Delta_l) = \llbracket \Psi_o, \Psi''; \Delta_o \rrbracket$ 
for some variable 
context $\Psi''$ containing destinations free in the first translated
context but not the second.
\end{theorem}

\begin{proof}
As in \cite[Theorem 2]{simmons11logical}.
\end{proof}


If we leave off explicitly mentioning the variable context $\Psi$, 
then the trace that represents successfully processing 
the string {\sf [ ( ) ] }
with the transformed push-down automaton 
specification in Figure~\ref{fig:pda-lin} 
is as follows (we again underline ${\sf hd}$
for emphasis):
\begin{align*}
           & y_0{:}\susp{\underline{\sf hd}\,\lf{d_0}\,\lf{d_1}},
             x_1{:}\susp{{\sf left}\,{\sf sq}\,\lf{d_1}\,\lf{d_2}},
             x_2{:}\susp{{\sf left}\,{\sf pa}\,\lf{d_2}\,\lf{d_3}},
             x_3{:}\susp{{\sf right}\,{\sf pa}\,\lf{d_3}\,\lf{d_4}},
             x_4{:}\susp{{\sf right}\,{\sf sq}\,\lf{d_4}\,\lf{d_5}}
\\
\leadsto ~ & z_1{:}\susp{{\sf stack}\,{\sf sq}\,\lf{d_0}\,\lf{d_6}},
             y_1{:}\susp{\underline{\sf hd}\,\lf{d_6}\,\lf{d_2}},
             x_2{:}\susp{{\sf left}\,{\sf pa}\,\lf{d_2}\,\lf{d_3}},
             x_3{:}\susp{{\sf right}\,{\sf pa}\,\lf{d_3}\,\lf{d_4}},
             x_4{:}\susp{{\sf right}\,{\sf sq}\,\lf{d_4}\,\lf{d_5}}
\\
\leadsto ~ & z_1{:}\susp{{\sf stack}\,{\sf sq}\,\lf{d_0}\,\lf{d_6}},
             z_2{:}\susp{{\sf stack}\,{\sf pa}\,\lf{d_6}\,\lf{d_7}},
             y_2{:}\susp{\underline{\sf hd}\,\lf{d_7}\,\lf{d_3}},
             x_3{:}\susp{{\sf right}\,{\sf pa}\,\lf{d_3}\,\lf{d_4}},
             x_4{:}\susp{{\sf right}\,{\sf sq}\,\lf{d_4}\,\lf{d_5}}
\\
\leadsto ~ & z_1{:}\susp{{\sf stack}\,{\sf sq}\,\lf{d_0}\,\lf{d_6}},
             y_3{:}\susp{\underline{\sf hd}\,\lf{d_6}\,\lf{d_4}},
             x_4{:}\susp{{\sf right}\,{\sf sq}\,\lf{d_4}\,\lf{d_5}}
\\
\leadsto ~ & y_4{:}\susp{\underline{\sf hd}\,\lf{d_0}\,\lf{d_5}}
\end{align*}


\begin{figure}[t]
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-vestige.sls}
\caption{Translation of Figure~\ref{fig:cbv-ev-ssos-fun} with vestigial destinations}
\label{fig:dest-vestige}
\end{figure}

\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-cbv.sls}
\caption{Translation of Figure~\ref{fig:cbv-ev-ssos-fun} without vestigial destinations}
\label{fig:dest-cbv}
\end{figure}



\subsection{Vestigial destinations}
\label{sec:vestigial}

When we apply the translation of expressions to the call-by-value
lambda calculus specification from Figure~\ref{fig:cbv-ev-ssos-fun},
we get the specification in Figure~\ref{fig:dest-vestige}.  This
specification has one problem: the second argument to ${\sf eval}$ and
${\sf retn}$ is always $\lf{d'}$, and the destination never changes; it is
essentially a vestige of the destination-adding transformation. As
long as we are transforming a sequential ordered abstract machine, we
can eliminate this vestigial destination, giving us the specification
in Figure~\ref{fig:dest-cbv}. This extra destination is {\it not}
vestigial when we translate a parallel specification, but as we
discuss in Section~\ref{sec:modular-parallelism}, we don't necessarily
want to apply destination-adding to parallel ordered abstract machines
anyway.

\subsection{Persistent destination passing}
\label{sec:persistentdestpass}

When we translate our PDA specification, it is actually not necessary
to translate ${\sf hd}$, ${\sf left}$, ${\sf right}$ and ${\sf stack}$ as
linear atomic propositions. If we translate ${\sf hd}$ as
a linear predicate but translate the other predicates as persistent
predicates, it will still be the case that there is always exactly one
linear atomic proposition ${\sf hd}\,\lf{d_L}\,\lf{d_R}$ 
in the context, at most one
${\sf stack}\,\lf{x}\,\lf{d}\,\lf{d_L}$ 
proposition with the same destination $\lf{d_L}$, 
and at most one ${\sf right}\,\lf{x}\,\lf{d_R}\,\lf{d}$ or 
${\sf left}\,\lf{x}\,\lf{d_R}\,\lf{d}$ 
with the same destination $\lf{d_R}$. This means it is still the case that the
PDA accepts the string if and only if there is the following series of 
transitions:
\begin{align*}
 %(d_0{:}{\sf dest}, \ldots, d_{n+1}{:}{\sf dest}; 
(    x{:}\susp{{\sf hd}\,\lf{d_0}\,\lf{d_1}}, 
    y_1{:}\susp{{\sf left}\,\lf{x_1}\,\lf{d_1}\,\lf{d_2}},
    \ldots&,
    y_n{:}\susp{{\sf right}\,\lf{x_n}\,\lf{d_n}\,\lf{d_{n+1}}})% )
%\\
% &
~~ \leadsto^* ~~
%   (\Psi; 
(\Gamma, z{:}\susp{{\sf hd}\,\lf{d_0}\,\lf{d_{n+1}}})%)
\end{align*}
Unlike the entirely-linear PDA specification, the final state may include
some additional 
persistent propositions, represented by $\Gamma$. Specifically, the final state
contains all the original ${\sf left}\,\lf{x}\,\lf{d_i}\,\lf{d_{i+1}}$ and
${\sf right}\,\lf{x}\,\lf{d_i}\,\lf{d_{i+1}}$ propositions 
along with all the ${\sf stack}\,\lf{x}\,\lf{d}\,\lf{d'}$ 
propositions that were created
during the course of evaluation.

% \begin{figure}[t]
% \fvset{fontsize=\small,boxwidth=229pt}
% \VerbatimInput{sls/pda-pers.sls}
% \caption{Linear/persistent \sls~specification of a PDA for parenthesis
%   matching.}
% \label{fig:pda-pers}
% \end{figure}

I originally conjectured that a version of
Theorem~\ref{thm:destcorrect} would hold in any specification that
turned some ordered atomic propositions linear and others
persistent just as long as at least one atomic proposition in
the premise of every rule remained linear after transformation.  
This would have given a
generic justification for turning ${\sf left}$, ${\sf right}$ and ${\sf
  stack}$ persistent in Figure~\ref{fig:pda-lin} and to turning ${\sf
  cont}$ persistent in Figure~\ref{fig:dest-cbv}. However, that
condition is not strong enough.  To see why, consider a signature with
one rule, ${\sf a} \fuse {\sf b} \fuse {\sf a} \lefti \{ {\sf b} \}$,
where ${\sf a}$ and ${\sf b}$ are ordered atomic propositions.  We can
construct the following trace:
\begin{align*}
& (x_1{:}\susp{\sf a}, x_2{:}\susp{\sf b}, x_3{:}\susp{\sf a}, 
  x_4{:}\susp{\sf b}, x_5{:}\susp{\sf a})
\leadsto 
(x{:}\susp{\sf b},
  x_4{:}\susp{\sf b}, x_5{:}\susp{\sf a})
\not\leadsto  
\intertext{From the same starting point, exactly one
other trace is possible:}
& (x_1{:}\susp{\sf a}, x_2{:}\susp{\sf b}, x_3{:}\susp{\sf a}, 
  x_4{:}\susp{\sf b}, x_5{:}\susp{\sf a})
\leadsto 
(x_1{:}\susp{\sf a}, x_2{:}\susp{\sf b}, x{:}\susp{\sf b})
\not\leadsto 
\end{align*}
However, if we perform the destination-passing transformation, letting
${\sf a}\,\lf{d}\,\lf{d'}$ be a persistent atomic proposition and letting ${\sf
  b}\,\lf{d}\,\lf{d'}$ be a linear atomic proposition, then we have a series of
transitions in the transformed specification that can reuse the atomic
proposition ${\sf a}\,\lf{d_2}\,\lf{d_3}$ in a way that doesn't correspond to
any series of transitions in ordered logic:
\begin{align*}
&  x_1{:}\susp{{\sf a}\,\lf{d_0}\,\lf{d_1}}, 
   x_2{:}\susp{{\sf b}\,\lf{d_1}\,\lf{d_2}}, 
   x_3{:}\susp{{\sf a}\,\lf{d_2}\,\lf{d_3}}, 
   x_4{:}\susp{{\sf b}\,\lf{d_3}\,\lf{d_4}}, 
   x_5{:}\susp{{\sf a}\,\lf{d_4}\,\lf{d_5}}
\\ \leadsto~
&  x_1{:}\susp{{\sf a}\,\lf{d_0}\,\lf{d_1}}, 
   \underline{x{:}\susp{{\sf b}\,\lf{d_0}\,\lf{d_3}}}, 
   x_3{:}\susp{{\sf a}\,\lf{d_2}\,\lf{d_3}}, 
   x_4{:}\susp{{\sf b}\,\lf{d_3}\,\lf{d_4}}, 
   x_5{:}\susp{{\sf a}\,\lf{d_4}\,\lf{d_5}}
\\ \leadsto~
&  x_1{:}\susp{{\sf a}\,\lf{d_0}\,\lf{d_1}}, 
   x{:}\susp{{\sf b}\,\lf{d_0}\,\lf{d_3}}, 
   x_3{:}\susp{{\sf a}\,\lf{d_2}\,\lf{d_3}}, 
   \underline{x'{:}\susp{{\sf b}\,\lf{d_2}\,\lf{d_5}}}, 
   x_5{:}\susp{{\sf a}\,\lf{d_4}\,\lf{d_5}}
\end{align*}
In the
first process state, there is a path 
$\lf{d_0}, \lf{d_1}, \lf{d_2}, \lf{d_3}, \lf{d_4}, \lf{d_5}$ through
the context that reconstructs the ordering in the original ordered context.
In the second process state, there is still a path 
$\lf{d_0}, \lf{d_3}, \lf{d_4}, \lf{d_5}$ that
allows us to reconstruct the ordered context
$(x{:}\susp{\sf b},
  x_4{:}\susp{\sf b}, x_5{:}\susp{\sf a})$ by ignoring the persistent
propositions associated with $x_1$ and $x_3$. 
However, in the third process state above, no path exists, so the final
state cannot be reconstructed as any ordered context. 

It would be good to identify a condition that allowed us to
selectively turn some ordered propositions persistent when
destination-adding without violating (a version of)
Theorem~\ref{thm:destcorrect}. In the absence of such a generic
condition, it is still straightforward to see that performing
destination-passing and then turning some propositions persistent is
an {\it abstraction}: if the original system can make a series of
transitions, the transformed system can simulate those transitions,
but the reverse may not be true. For systems we are interested in
(like push-down automata with persistent ${\sf stack}$, ${\sf left}$,
and ${\sf right}$ or the sequential ordered abstract machines with
persistent ${\sf cont}$), it happens to be the case that the
abstraction is precise: the partially-persistent destination-passing
specification can only make transitions that were possible in the
ordered specification.

\section{Exploring the richer fragment}

In \cite{simmons11logical}, we were interested in exact logical
correspondence between ordered abstract machine SSOS specifications
and destination-passing SSOS specifications. (Destination-adding was
useful in that context because it exposes information about the
control structure of computations; this control structure can be
harnessed by the program abstraction methodology described in the next
chapter to derive program analyses.) In keeping with our broader use
of the logical correspondence, this section will cover programming
language features that are not easily expressible with ordered
abstract machine SSOS specifications but that can be easily expressed
with destination-passing SSOS specifications. Consequently, these are
features that can be modularly added to (sequential) ordered abstract
machine specifications that have undergone the destination-adding
transformation.

The semantics of parallelism and failure presented in
Section~\ref{sec:modular-parallelism} are new. The semantics of
futures (Section~\ref{sec:dest-futures}) and synchronization
(Section~\ref{sec:dest-synch}) are a based on the specifications first
presented in the CLF tech report \cite{cervesato02concurrent}. The
semantics of first-class continuations
(Section~\ref{sec:dest-continuations}) were presented previously in
\cite{pfenning04substructural,pfenning09substructural}. In
destination-passing semantics, when we are dealing with fine-grained
issues of control flow, the interaction of programming language
features becomes more delicate.  Parallel evaluation, recoverable
failure, and synchronization are compatible features, as are
synchronization and futures. Failure and first-class continuations are
also compatible. We will not handle other interactions, though it
would be interesting to explore the adaptation of Moreau and Ribbens'
abstract machine for Scheme with parallel evaluation and ${\sf
  callcc}$ as a substructural operational semantics
\cite{moreau96semantics}.

\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-pair.sls}
\caption{Destination-passing semantics for parallel evaluation of pairs}
\label{fig:dest-pair}
\end{figure}

\subsection{Alternate semantics for parallelism and exceptions}
\label{sec:modular-parallelism}

In Section~\ref{sec:failure}, we discussed how parallel evaluation and
recoverable failure can be combined in an ordered abstract machine
SSOS specification. Due to the fact that the two parts of a parallel
ordered abstract machine are separated by an arbitrary amount of
ordered context, some potentially desirable ways of
integrating parallelism and failure were difficult or impossible to
express, however. 

Once we transition to destination-passing SSOS specifications, it is
possible to give a more direct semantics to parallel evaluation that
better facilitates talking about failure. Instead of having the stack
frame associated with parallel pairs be ${\sf cont}\,\lf{\sf pair1}$ (as
in Figure~\ref{fig:ssos-minml-core}) or ${\sf cont2}\,\lf{\sf pair1}$ (as
discussed in Section~\ref{sec:failure}), we create a continuation
${\sf cont2}\,\lf{\sf pair1}\,\lf{d_1}\,\lf{d_2}\,\lf{d}$ 
with {\it three} destinations;
$\lf{d_1}$ and $\lf{d_2}$ represent the return destinations for the two
subcomputations, whereas $\lf{d}$ represents the destination to which the
evaluated pair is to be returned. This strategy applied to the
parallel evaluation of pairs is shown in Figure~\ref{fig:dest-pair}.

In ordered specifications, an ordered atomic proposition can be
directly connected to at most two other ordered propositions: the
proposition immediately to the left in the ordered context, and the
proposition immediately to the right in the ordered context. What
Figure~\ref{fig:dest-pair} demonstrates is that, with destinations, a
linear proposition can be locally connected to {\it any finite number}
of other propositions. Whereas in ordered abstract machine
specifications the parallel structure of a computation had to be
reconstructed by parsing the context in postfix, a linear
destination-passing specification uses destinations to thread together
the treelike dependencies in the context. It would presumably be
possible to consider a different version of the parallel
operationalization that targeted this form of destination-passing
specification specifically, but we will not consider such a
transformation in this thesis. 

\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-fail-paror.sls}
\caption{Integration of parallelism and exceptions; signals failure as
  soon as possible}
\label{fig:dest-fail-paror}
\end{figure}

Using destination-based parallel continuations, we give, in
Figure~\ref{fig:dest-fail-paror}, a semantics for recoverable failure
that eagerly returns errors from either branch of a parallel
computation. The rules ${\sf ev/errorL}$ and ${\sf ev/errorR}$
immediately pass on errors returned to a frame where the computation
forked.  Those two rules also leave behind a linear proposition ${\sf
  terminate}\,\lf{d}$ that will abort the other branch of computation if it
returns successfully (rule ${\sf term/retn}$) or with an error (rule
${\sf term/err}$). It would also be possible to add rules
like $\forall \lf{d}.\,\forall\lf{d'}.\,{\sf cont}\,\lf{d'}\,\lf{d} \fuse {\sf terminate}\,\lf{d} \lefti \{ {\sf
  terminate}\,\lf{d'} \}$ that actively aborted the useless branch instead
of passively waiting for it to finish.

\subsection{Synchronization}
\label{sec:dest-synch}

The CLF tech report gives a destination-passing presentation of the
nearly the full set of Concurrent ML primitives, omitting only
negative acknowledgements \cite{cervesato02concurrent}. We will
present an \sls~version of that Concurrent ML specification as a part
of the hybrid specification in Appendix~\ref{chapter-appendix-hybrid}.
In Figure~\ref{fig:dest-synch}, rather than reprising that
specification, we present an extremely simple form of synchronous
communication.


\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-synch.sls}
\caption{Semantics of simple synchronization}
\label{fig:dest-synch}
\end{figure}

New channels are created by the evaluating $\interp{{\sf chan}\,c.e} =
\lf{{\sf chan}\,\lambda c.\,\interp{e}}$, which introduces a new channel
(an LF term of the type ${\sf channel}$ that has no constructors and
substituted it for the bound $\lf{c}$ in $\obj{e}$). 
Synchronization happens when
there is both a send $\obj{{\sf send}\,c\,e}$ in one computation and a
receive $\obj{{\sf recv}\,c}$ in a different computation along the same
channel. The expression $\obj{e}$ will first evaluate to a value $\obj{v}$ 
(rule ${\sf ev/send}$). Communication is
driven by rule ${\sf ev/send1}$, which allows computation to continue
in both the sender and the receiver.

Synchronous communication introduces the possibility of
deadlocks. Without synchronous communication, the presence of a
suspended atomic proposition ${\sf eval}\,\lf{e}\,\lf{d}$ always
indicates the possibility of some transition, and the combination of a
proposition ${\sf retn}\,\lf{v}\,\lf{d}$ and a continuation ${\sf
  cont}\,\lf{f}\,\lf{d}\,\lf{d'}$ can either immediately transition or
else are permanently in a stuck
state. In~\cite{pfenning09substructural}, this observation motivated a
classification of atomic propositions as {\it active} propositions
like ${\sf eval}\,\lf{e}\,\lf{d}$ that independently drive
computation, {\it passive} propositions like ${\sf
  cont}\,\lf{f}\,\lf{d'}\,\lf{d}$ that do not drive computation, and
{\it latent} propositions like ${\sf retn}\,\lf{f}\,\lf{d}$ that may
or may not drive computation based on the ambient environment of
passive propositions. The specification in Figure~\ref{fig:dest-synch}
does not respect this classification because a proposition of the form
${\sf eval}\,\lf{({\sf recv}\,c)}\,\lf{d}$ cannot immediately
transition. We could restore this classification by having a rule
$\forall \lf{c}.\,\forall \lf{d}.\, {\sf eval}\,\lf{({\sf
    recv}\,c)}\,\lf{d} \lefti \{ {\sf await}\,\lf{c}\,\lf{d} \}$ for
some new passive linear predicate ${\sf await}$ and then replacing the
premise ${\sf eval}\,\lf{({\sf recv}\,C)}\,\lf{D}$ in ${\sf ev/send1}$
with ${\sf await}\,\lf{C}\,\lf{D}$.

\subsubsection{Labeled transitions}

Substructural  operational semantics  are a  very continuation-focused
formalism.  Continuations  are not  always  the  most  natural way  to
express a specification, and this observation motivated our discussion
of  the operationalization transformation  from natural  semantics and
our  informal discussion  of statefully-modular  natural  semantics in
Section~\ref{sec:enriching-natsem}.  In Chapter~6,  we showed that the
continuation-focused  perspective   of  SSOS  allowed   us  to  expose
computation to the ambient  state. With the example of synchronization
above, we see that destination-passing SSOS specifications also expose
computations in  the process state to {\it  other computations}, which
is what  allows the synchronization  in rule ${\sf ev/send1}$  to take
place.

In small-step operational
semantics, {\it labeled deduction} is used to describe specifications like
the one above. We inductively define a small step judgment 
$\obj{e ~{\stackrel{\footnotesize{\it lab}}{\longmapsto}}~
e'}$ with the property that
\smallskip
\begin{itemize}
\item $\obj{e ~{\stackrel{\footnotesize{c{\textbf{!}}v}}{\longmapsto}}~
e'}$ if $\obj{e}$ steps to $\obj{e'}$ by reducing some subterm 
$\obj{{\sf send}\,c\,v}$,
to $\obj{\langle\rangle}$,
\item $\obj{e
~{\stackrel{\footnotesize{c{\textbf{?}}v}}{\longmapsto}}~ e'}$ if $\obj{e}$
steps to $\obj{e'}$ by reducing some subterm $\obj{{\sf recv}\,c}$ to 
$\obj{v}$, and 
\item $\obj{e_1}$ in parallel with $\obj{e_2}$ can step to $\obj{e_1'}$
in parallel with $\obj{e_2'}$ if $\obj{e_1
~{\stackrel{\footnotesize{c{\textbf{!}}v}}{\longmapsto}}~ e_1'}$ and
$\obj{e_2 ~{\stackrel{\footnotesize{c{\textbf{?}}v}}{\longmapsto}}~ e_2'}$.
\end{itemize}
\smallskip
Labels essentially serve to pass messages up through the inductive
structure of a proposition.  In destination-passing SSOS semantics, on
the other hand, the internal structure of $e$ is spread out as a
series of continuation frames throughout the context, and so the
innermost redexes of terms can be directly connected. It would be
interesting (but probably quite nontrivial) to consider a translation
from labeled deduction systems to destination-passing SSOS
specifications along the lines of the operationalization
transformation.


\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-futures.sls}
\caption{Semantics of call-by-future functions}
\label{fig:dest-futures}
\end{figure}

\subsection{Futures}
\label{sec:dest-futures}

Futures can be seen as a parallel version of call-by-value, and the
presentation in Figure~\ref{fig:dest-futures} can be compared to the
environment semantics for call-by-value in
Figure~\ref{fig:ssos-by-env}. We introduce future-functions as a new
kind of function $\lf{{\sf flam}\,\lambda x.e}$ comparable to plain-vanilla
call-by-value functions $\lf{{\sf lam}\,\lambda x.e}$, lazy call-by-need
functions $\lf{{\sf lazylam}\,\lambda x.e}$, and environment-semantics
functions $\lf{{\sf envlam}\,\lambda x.e}$. As in the environment semantics
specification, when a call-by-future function returns to a frame
$\interp{\Box\,e_2} = \lf{{\sf app1}\,\interp{e_2}}$,
 we create a new expression $\lf{x}$
by existential quantification. However, instead of suspending the
function body on the stack as we did in Figure~\ref{fig:ssos-by-env},
in Figure~\ref{fig:dest-futures} we create a new destination $\lf{\it
  dfuture}$ and start evaluating the function argument towards that
destination (rule ${\sf ev/fapp1}$). We also create a linear
proposition -- ${\sf promise}\,\lf{\it dfuture}\,\lf{x}$ -- that will take
any value returned to $\lf{\it dfuture}$ and permanently bind it to $\lf{x}$
(rule ${\sf ev/promise}$). As a proposition that only exists during
the course of evaluating the argument, ${\sf promise}$ is analogous to
the black hole in our specification of lazy call-by-need.

Futures illustrate the use of destination-passing to create new and
potentially disconnected threads of computation. This was not possible
in the ordered framework where every computation had to be somewhere
specific in the ordered context relative to the current computation --
either to the left, or to the right. The destination-passing semantics
of futures interact seamlessly with the semantics of
synchronization and parallelism, but not with the semantics of
recoverable failure: we would have to make some choice about what to 
do when a future signals failure.

%\footnote{``Like lazy evaluation, futures can be used to compute 
%nonstrict functions -- functions that terminate despite the 
%possible nontermination of the computation of one or more argument
%values.'' \cite{halsted85multilisp}}

\subsection{First-class continuations}
\label{sec:dest-continuations}

First-class continuations are a sophisticated control feature.
{\it Continuations} are another name for the stacks $\obj{k}$ 
in abstract machine
semantics with states $\obj{k \rhd e}$ and $\obj{k \lhd v}$ (and also,
potentially, $\obj{k {\blacktriangleleft}}$). First-class continuations
introduce a new value, $\obj{{\sf cont}\,k}$, to the language. Programmers
cannot write continuations $\obj{k}$ directly, just as they cannot write
locations $\obj{l}$ directly; rather, the expression $\interp{{\sf
    letcc}\,x.e} = \lf{{\sf letcc}\,\lambda x.\interp{e}}$ captures the
current expression as a continuation:
\begin{align*}
  \obj{k \rhd {\sf letcc}\,x.e} ~~&\obj{\mapsto}~~ \obj{k \rhd [{\sf cont}\,k/x]e}
  \intertext{There is a third construct, $\interp{{\sf
        throw}\,e_1\,{\sf to}\,e_2} = \lf{{\sf throw}\,\interp{e_1}\,\interp{e_2}}$ that
    evaluates $\obj{e_1}$ to a value $\obj{v_1}$, evaluates $\obj{e_2}$ to a
    continuation value $\obj{{\sf cont}\,k'}$, and then throws away the
    current continuation in favor of returning $\obj{v_1}$ to $\obj{k'}$:}  
  \obj{k \rhd {\sf throw}\,e_1\,{\sf to}\,e_2} ~~&\obj{\mapsto}~~
  \obj{(k; {\sf throw}\,\Box\,{\sf to}\,e_2) \rhd e_1}
  \\
  \obj{(k; {\sf throw}\,\Box\,{\sf to}\,e_2) \lhd v_1} ~~&\obj{\mapsto}~~ \obj{(k; {\sf
    throw}\,v_1\,{\sf to}\,\Box) \rhd e_2}
  \\
  \obj{(k; {\sf throw}\,v_1\,{\sf to}\,\Box) \lhd {\sf cont}\,k'} ~~&\obj{\mapsto}~~
  \obj{k' \lhd v_1}
\end{align*}
When handled in a typed setting, a programming language with
first-class continuations can be seen as a Curry-Howard interpretation
of classical logic.

\begin{figure}
\fvset{fontsize=\small,boxwidth=229pt}
\VerbatimInput{sls/dest-letcc.sls}
\caption{Semantics of first-class continuations (with ${\sf letcc}$)}
\label{fig:dest-letcc}
\end{figure}


In destination-passing SSOS specifications, we never represent
continuations or control stacks $\obj{k}$ directly. However, we showed in
Section~\ref{sec:nat-ssos-adequacy} that a control stack $\obj{k}$ is
encoded in the context as a series of ${\sf cont}$ frames. In a
destination-passing specification, it is therefore reasonable to
associate a $\obj{k}$ continuation with the destination $\lf{d}$ that points to
the topmost frame ${\sf cont}\,\lf{f}\,\lf{d}\,\lf{d'}$ in the stack 
$\obj{k}$ encoded in
the process state. Destinations therefore stand for continuations in
much the same way that introduced variables $\lf{x}$ in the environment
semantics stand for the values $\lf{v}$ they are bound to through
persistent ${\sf bind}\,\lf{x}\,\lf{v}$ propositions. In
Figure~\ref{fig:dest-letcc}, the rule ${\sf ev/letcc}$ captures the
current continuation $\lf{d}$ as an expression $\lf{{\sf cont}\,d}$ that is
substituted into the subexpression. In rule ${\sf ev/throw2}$, the
destination $\lf{{\sf cont}\,{\it dk}}$ gets the value $\lf{v_1}$ returned to
it; the previous continuation, represented by the destination $\lf{d}$, is
abandoned.

Just as it is critical for the ${\sf bind}$ predicate in the
environment semantics to be persistent, it is necessary, when dealing
with first-class-continuations, to have the ${\sf cont}$ predicate be
persistent. As discussed in Section~\ref{sec:persistentdestpass}, it
does not change the behavior of any SSOS specifications we have
discussed if linear ${\sf cont}$ predicates are turned into persistent
${\sf cont}$ predicates.
