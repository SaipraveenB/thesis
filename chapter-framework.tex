\chapter{Substructural logical specifications}
\label{chapter-framework}

Logical framework time!

The proof term interpretation of focused sequent calculi is a term
representation called {\it spine form}. 
a

\section{Spine Form LF as a term language}

Other substructural logical frameworks, like Cervesato and Pfenning's
LLF \cite{cervesato02linear}, Polakow's OLF \cite{polakow01ordered},
and Watkins et al.'s CLF \cite{watkins02concurrent} are {\it
  fully-dependent type theories}: the language of terms, the domain of
first-order quantification, is the same as the language of proof
terms, the representatives of logical derivations (we will call the
domain of quantification the {\it object terms} when ``terms'' would
be ambiguous). The logical framework \sls~presented in this chapter
breaks from this tradition. The language of first-order
quantification, which was left unspecified in Chapter 3, will be
presently described as Spine Form LF, a well-understood logical
framework derived from the normal forms of the purely persistent type
theory LF \cite{harper93framework}.

After addressing our reasons for this non-standard decision in
Section~\ref{sec:why-not-fully-dependent}, we will give a very basic
crash course on LF and its metatheory. All the information here is
standard and adequately presented between Harper, Honsell, and
Plotkin's original presentation of LF \cite{harper93framework},
Cervesato and Pfenning's discussion of spine form terms
\cite{cervesato02linear}, Watkins et al.'s presentation of the
canonical forms of CLF \cite{watkins02concurrent}, Harper and Licata's
discussion of Canonical LF \cite{harper07mechanizing}, and Reed's
spine form presentation of HLF \cite{reed09hybrid}. In particular, our
presentation attempts to mimics Harper and Licata's presentation from
\cite{harper07mechanizing}, except that we use a spine form
representation of terms. Canonical term languages correspond to normal
natural deduction proofs, whereas spine form term languages correspond
to focused sequent calculus proofs.

It would be entirely consistent for us to appropriate Harper and
Licata's Canonical LF presentation instead of presenting Spine Form
LF. Nevertheless, a spine-form presentation of canonical LF serves to
make our presentation more uniform, as spines are used in the proof
term language of \sls.

\subsection{Why LF as a term language?}
\label{sec:why-not-fully-dependent}

The decision to use LF as a first-order domain of quantification
rather than using a fully-dependent system is based on several
considerations. First and foremost, this choice was sufficient for the
purposes of this thesis. In fact, for the purposes of this thesis, we
could used an even simpler term language of simply-typed LF
\cite{pfenning08church}; two other logic programming interpretations
of \sls-like frameworks, Lollimon \cite{lopez05monadic} and Ollibot
\cite{pfenning09substructural}, were based on simply-typed term
languages. Canonical LF and Spine Form LF are, at this point,
well-understood enough that the additional overhead of fully
dependently-typed terms is not a significant burden, and there are
examples beyond the scope of this thesis where term dependency is
useful.

On a theoretical level, it is a significant simplification when we
restrict ourselves to {\it any} typed term language with a reasonable
notion of equality and substitution. Spine Form LF and Canonical LF
are two examples; most conceivable simply-typed term languages would
also suffice. It is the thesis of this and the previous two chapters
that we can productively derive logical frameworks from focused
presentations of logic, but this simple is complicated when we apply it
to a dependent type theory like CLF that does not distinguish object
terms and proof terms. CLF terms have a notion of {\it concurrent
  equivalence} which is coarser the equivalence relation described by
focusing alone, and we want \sls~proof terms to have a similar notion
of equivalence. In this chapter we characterize concurrent equivalence
in Section~\ref{XXX}, after completing our discussion of the framework
and describing the proof term language.  In CLF, the framework's
definition relies on term equality, and equality of terms must take
concurrent equivalence into account, so concurrent equivalence of
(proof) terms is conceptually prior to the logic itself. We conjecture
that this complication is no great obstacle, but this thesis avoids
the issue.

On a practical level, there are advantages to using a well-understood
term language. The \sls~prototype implementation
(Section~\ref{sec:prototype}) uses the mature type reconstruction
engine of Twelf. Schack-Nielsen's implementation of type
reconstruction for Celf is complicated by the requirements of dealing
with a substructural term language, and the user is required to add
extra annotations to indicate persistent application and abstraction
\cite{schacknielsen08celf}. In \sls~(and in many CLF encodings) the
term language is intended to be persistent, so these extra annotations
just clutter specifications.

The restriction to a dependent type theory therefore does not come at
the cost of great expressive power. Conversely, it is by no means
clear that the addition of full CLF-like dependency comes with great
expressive benefit. Even in LF and Twelf, many interesting
specifications could be encoded in a two-level version of the
language: a simply-typed object term language and a dependently-typed
proof term language with first-order quantification over object
terms. This restriction is sufficient for settings such as Harper's
comprehensive survey of programming language design
\cite{harper12practical},\footnote{Harper's metatheory also extends LF
  by drawing a distinction between standard variables and nominal
  parameters, but this is an orthogonal point.} and it is built in to
the educational proof assistant SASyLF \cite{aldrich08sasylf}. In LF
and Twelf, the ability to use full dependent types is critical in part
because it allows us to express {\it metatheorems} -- theorems about
the programming languages and logics we have encoded, like progress
and preservation for a programming language or cut admissibility for a
logic. But in substructural logical frameworks like Linear LF, full
dependency has been found to be {\it insufficient} for expressing
metatheorems, which motivated the development of Hybrid LF as a
framework for writing metatheorems about LF \cite{reed09hybrid}. The
implementation of Hybrid LF effectively creates a stratification like
\sls's -- full LF as an object term language, a linear logical
framework with first-order quantification over object language terms,
and a hybrid language that can inspect both LF object terms and linear
proof terms.

\subsection{Core syntax}

The syntax of Spine Form LF is extended in two places to handle \sls:
rules ${\sf r} : A^-$ in the signature contain negative \sls~types
$A^-$ (though it would be possible to separate out the LF portion of
signatures from the \sls~rules). We also add four additional kinds,
${\sf prop}$, which classifies negative ordered atomic types $p^-$,
${\sf prop}\,{\sf ord}$, which classifies positive ordered atomic
types $p^+$, ${\sf prop}\,{\sf lin}$, which classifies positive
linear/mobile/ephemeral atomic types $p^+_\meph$, and ${\sf
  prop}\,{\sf ord}$, which classifies positive persistent atomic types
$p^+_\mpers$. 

Other than the extra kinds classifying atomic \sls~propositions, kinds
$\kappa$ are otherwise exactly as they are in other presentations of
LF; kinds classify types $\tau$, and types $\tau$ classify normal
terms $\lf{t}$ and spines $\lf{\spi}$.
\begin{align*}
& \mbox{Signatures} & \Sigma & ::= \cdot 
  \mid \Sigma, \lf{\sf c} : \tau
  \mid \Sigma, {\sf a} : \kappa
  \mid \Sigma, {\sf r} : A^-
\\
& \mbox{Variable contexts} & \Psi & ::= \cdot
  \mid \Psi, \lf{x} {:} \tau 
\\
& \mbox{Kinds} & \kappa & ::= \lfpi{x}{\tau}{\kappa} \mid {\sf type}
  \mid {\sf prop}
  \mid {\sf prop}\,{\sf ord}
  \mid {\sf prop}\,{\sf lin}
  \mid {\sf prop}\,{\sf pers}
\\
& \mbox{Types} & \tau & ::= \lfpi{x}{\tau}{\tau'} \mid \lfroot{\sf a}{\spi}
\\
& \mbox{Heads} & \lf{h} & ::= \lf{x} \mid \lf{\sf c}
\\
& \mbox{Normal terms} & \lf{t} & ::= \lf{\lambda x.t}
  \mid \lf{\lfroot{h}{\spi}}
\\
& \mbox{Spines} & \lf{\spi} & ::= \lf{t; \spi} \mid \lf{\lfnil}
\end{align*}

According to the typing rules, a lambda $\lf{\lambda x.t}$ is
classified by a dependent type $\lfpi{x}{\tau}{\tau'}$, whereas an
atomic term $\lf{\lfroot{h}{\spi}}$ is classified by an atomic type
$\lfroot{\sf a}{\spi'}$. LF spines $\lf\spi$ are just sequences of
terms $\lf{(t_1; (\ldots; (t_n;())\ldots))}$; we will follow common
convention and write $\lf{h\,t_1\ldots t_n}$ as a convenient shorthand
for the atomic term $\lf{\lfroot{h}{(t_1; \ldots; (t_n;())\ldots)}}$;
similarly, we will write ${\sf a}\,\lf{t_1\ldots t_n}$ as a shorthand
for both atomic types and propositions $\lfroot{\sf
  a}{(t_1; (\ldots; (t_n;())\ldots))}$.

\subsection{Adequacy}

$\interp{\obj{\lambda x.e}} = \lf{{\sf lam}\,\lambda x. \interp{\obj{e}}}$

\section{Carving out a logical framework}


Talk about Jason's thesis \cite{}. Talk about the pain of concurrent 
equality \cite{}.

\subsection{Deductive terms}

\subsection{Concurrent traces}
\label{sec:framework-substprop}


(Talk about the notation $\tackon{\Theta}{C^+}$, there's a backwards
reference to this section)

\subsection{Concurrent equality}

\subsection{Concurrent equality}
\label{sec:linconcurrenteq}

Concurrent equality is a notion of equivalence that operates on
synthetic derivations.  It represents an intermediate point between
focusing and multifocusing \cite{chaudhuri08canonical}.  Consider the
sequent in focused linear logic:
\[
\mildseq{a^+ \lolli {\uparrow}(b^+ \otimes c^+), ~
  b^+ \lolli {\uparrow}d^+, ~
  c^+ \lolli {\uparrow}e^+, ~
  d^+ \otimes e^+ \lolli {\uparrow}f^+ ~~}
  {~~
  \langle a^+ \rangle
  ~~}
  {~~f^+}
\]
Let $\Gamma = \left(a^+ \lolli {\uparrow}(b^+ \otimes c^+), ~
  b^+ \lolli {\uparrow}d^+, ~
  c^+ \lolli {\uparrow}e^+, ~
  d^+ \otimes e^+ \lolli {\uparrow}f^+ \right)$.
There are two different focused derivations of this
sequent: the one that transitions $\langle b^+ \rangle$ to $\langle
d^+ \rangle$ first, and the one that transitions 
$\langle c^+ \rangle$ to $\langle e^+ \rangle$ first:
\[
\infer
{\mildseq{\Gamma}{\langle a^+ \rangle}{f^+}}
{\infer
{\mildseq{\Gamma}{\langle b^+ \rangle, \langle c^+ \rangle}{f^+}}
{\infer
{\mildseq{\Gamma}{\langle d^+ \rangle, \langle c^+ \rangle}{f^+}}
{\infer
{\mildseq{\Gamma}{\langle d^+ \rangle, \langle e^+ \rangle}{f^+}}
{\infer
{\mildseq{\Gamma}{\langle f^+ \rangle}{f^+}}
{}}}}}
\qquad
\deduce
{\mathstrut}
{\deduce
{\mathstrut}
{\deduce
{\mathstrut}
{\mbox{\it vs.}}}}
\qquad
\infer
{\mildseq{\Gamma}{\langle a^+ \rangle}{f^+}}
{\infer
{\mildseq{\Gamma}{\langle b^+ \rangle, \langle c^+ \rangle}{f^+}}
{\infer
{\mildseq{\Gamma}{\langle b^+ \rangle, \langle e^+ \rangle}{f^+}}
{\infer
{\mildseq{\Gamma}{\langle d^+ \rangle, \langle e^+ \rangle}{f^+}}
{\infer
{\mildseq{\Gamma}{\langle f^+ \rangle}{f^+}}
{}}}}}
\]
If we think about these two proofs in terms of the series of
transitions they embody, it's not so clear we want to think of them as
different. In both cases, there is an $a^+$ resource that transitions
to a $b^+$ resource and a $c^+$ resource, and then $b^+$ transitions
to $d^+$ while, independently, the $c^+$ transitions to $e^+$. Then,
finally, the $d^+$ and $e^+$ combine to transition to $f^+$, which
completes the trace. The independence here is key: if two focusing
phases consume different resources and both end focus with
${\uparrow}_L$ (as opposed to ${\it id}^-$), then we can treat them as
independent and concurrent steps in the process of proving the same
right-hand side. {\it Concurrent equality} is the equivalence relation
on focused proofs that treats all proofs that differ only in the
interleaving of independent and concurrent steps as equal.  This
equivalence relation was used in the definition of CLF
\cite{watkins02concurrent}, but in a greatly restricted way that will
be reflected in Chapter 4.

Concurrent equality gives rise to an equivalence relation on focused
derivations. This equivalence relation is related to the equivalence
relation induced by {\it multifocusing}
\cite{chaudhuri08canonical}. Multifocusing is a concept that has only
been carefully explored in classical linear logic; the central change
is that the rules which begins a focusing phase (in our presentation
of MELL there were three: ${\it focus_L}$, ${\it focus_R}$, and ${\it
  copy}$) are allowed to simultaneously pull other propositions into
focus.  As an illustration, if we reuse our notation from
Section~\ref{sec:linnote} we can present the following plausible
candidates for the multifocus rules in an intuitionistic system:
\[
\infer[{\it focus}_L]
{\mildseq{\Gamma}{\Delta / A_1^-, \ldots, A_n^- }{U}}
{n > 1
 &
 \mildseq{\Gamma}{\Delta, [A_1^-], \ldots, [A_n^-]}{U}}
\quad
\infer[{\it focus}_R]
{\mildseq{\Gamma}{\Delta / A_1^-, \ldots, A_n^-}{C^+}}
{n \geq 1
 &
 \mildseq{\Gamma}{\Delta, [A_1^-], \ldots, [A_n^-]}{[C^+]}}
\]
Multifocusing, however,
appears to provide an even coarser notion of equivalence on focused
proofs than concurrent equality does. In particular, the two
distinct focusing proofs below are not concurrently equal: the proof
on the right succeeds at proving $\langle c^- \rangle$ in one step,
but leaves a subgoal in which $b^+$ is proved indirectly, whereas the
proof at the right first transitions from having $\langle a^+ \rangle$
and $a^+ \lolli {\uparrow} b^+$ resources to having a $\langle b^+
\rangle$ resource, and only then proves $\langle c^- \rangle$, leaving
a subgoal in which $b^+$ is proved directly.
\[
\infer
{\mildseq{\cdot}
  {~~
   \langle a^+ \rangle, ~
   a^+ \lolli {\uparrow}b^+, ~
   {\downarrow}{\uparrow}b^+ \lolli c^-
   ~~}
  {~~\langle c^- \rangle}}
{\infer
{\mildseq{\cdot}
  {~~
   \langle a^+ \rangle, ~
   a^+ \lolli {\uparrow}b^+
   ~~}
  {b^+}}
{\infer
{\mildseq{\cdot}
  {~~
   \langle b^+ \rangle
   ~~}
  {b^+}}
{}}}
\deduce{\mathstrut}
{\deduce{\mathstrut}
{\mbox{\it vs.}\mathstrut}}
\infer
{\mildseq{\cdot}
  {~~
   \langle a^+ \rangle, ~
   a^+ \lolli {\uparrow}b^+, ~
   {\downarrow}{\uparrow}b^+ \lolli c^-
   ~~}
  {~~\langle c^- \rangle}}
{\infer
{\mildseq{\cdot}
  {~~
   \langle b^+ \rangle, ~
   {\downarrow}{\uparrow}b^+ \lolli c^-
   ~~}
  {~~\langle c^- \rangle}}
{\infer
{\mildseq{\cdot}
  {~~
   \langle b^+ \rangle
   ~~}
  {~~b^+}}
{}}}
\]
Despite the lack of a full account of intuitionistic multifocusing, we
can observe that the analogue of this sequent in classical linear
logic has only one multifocused proof, and it is reasonable to
conjecture that an account of multifocusing for intuitionistic logic
would also relate these proofs. In classical linear logic,
multifocusing offers a very fundamental normal form: any two proofs
that can be made equal by locally permuting inference rules have the
same multifocused proof.

CLF's restricted form of concurrent equality will be sufficient for
the logical framework in Chapter 4. In fact, for the fragment of the
the logic in Chapter 3 that comprises our logical framework in Chapter
4, I conjecture that concurrent equality and the equality given by
multifocusing coincide.\footnote{This obviously means that the example
  above will be outside the logical fragment that comprises the logical
  framework.}  This conjecture is obviously difficult to make precise,
much less prove, without a general theory of multifocusing in
intuitionistic logic.


\subsection{A warning about normalization}
\label{sec:warning}

In our earlier discussion of hereditary substitution and canonical
forms in Section~\ref{sec:linlogicalframeworks}, we mentioned that the
normalization theorem provided by hereditary substitution was weaker
than the so-called weak normalization theorem for LF. That is because
the weak normalization theorem says that any well-typed term can be
converted into a canonical ($\beta$-normal and $\eta$-long) term by a
particular series of $\beta$ and $\eta$ conversions. It is
self-evident, by this statement of the theorem, that the resulting
canonical term is equivalent to the original term.

On the other hand, when we use hereditary substitution in the obvious
way to obtain a Canonical LF term from an arbitrary non-canonical LF
term, we gain {\it no guarantees} about the relationship between the
non-canonical LF term and the Canonical LF term. The statement of the
theorem does not preclude taking a $\beta$-normal, $\eta$-long LF term
(like $\lambda x. \lambda y. x$ of type $p \rightarrow p \rightarrow
p$ for some atomic type $p$) into a structurally different Canonical
LF term (like $\lambda x. \lambda y. y$, which also has type $p
\rightarrow p \rightarrow p$). It is possible to gain such a guarantee
for LF, as Martens and Crary have shown in unpublished work
\cite{martens11mechanizing}, but this result is a non-trivial statement
about the constructive content of the normalization theorem. 

In our setting, we should be concerned that we might take a focused
proof, turn it into an unfocused proof by the obvious de-focalization
procedure (the constructive content of
Theorem~\ref{thm:linfocsound}), and then turn it back into a focused
proof by focalization (the constructive content of
Theorem~\ref{thm:linfoccomplete}) only to obtain a proof that was not
identical or even related. This is not at all a merely hypothetical
concern. We can run the mechanized structural focalization result from
\cite{simmons11structural} on a persistent proposition,
%
   $a^+ \supset 
   {\downarrow}(a^+ \supset {\uparrow}b^+) \supset
   {\downarrow}({\downarrow}{\uparrow}b^+ \supset c^-) \supset
   c^-$, 
%
which is similar to the example from
Section~\ref{sec:linconcurrenteq}.  In persistent logic (as in
linear logic) that proposition has two focused propositions that
are probably multifocusing equivalent (given a reasonable intuitionistic
notion of multifocusing) but that are not concurrently equivalent
under the proposed definition of concurrent equality. 
However, if we take the focused proof that focuses 
first on $a^+ \supset {\uparrow}b^+$, transform it into an unfocused 
proof, and then re-focus it, we will get the proof that focuses 
first on ${\downarrow}{\uparrow}b^+ \supset c^-$. Focalization,
in other words, is not a partial inverse of de-focalization in the structural
focalization development, except maybe modulo the (as yet undefined)
equivalence relation established by multifocusing. 

This example illustrates why we must be careful, but it is not a fatal
flaw for two reasons. The first reason is the aforementioned
conjecture that, for the restricted logical fragment defined in
Chapter 4 as the basis of our logical framework, the focalizations of
two proofs are concurrently equal if and only if the original proofs
are convertible by local permutations of rules, the same condition
that multifocusing satisfies. If this conjecture holds, it ought to be
the case that, modulo this coarser equivalence, focalization {\it is}
a partial inverse of de-focalization. Second, what is really at stake
here is our ability to write down non-normal proofs in a logical
framework that then normalizes them -- which is what the Twelf
implementation of LF and the Celf implementation of CLF do -- with the
confidence that we can look at a non-normal proof and know its
corresponding canonical form. In this thesis, we will be content to
work throughout with focused proofs and their analogues, so we can
afford to leave questions about convertability and weak normalization
to future work.


\subsection{Pseudo-positive atoms}
\label{sec:pseudopositive}

\section{Adequate encoding}

The lambda
calculus usually has application $e_1\,e_2$ (encoded in LF as ${\sf
  app}\,\interp{e_1}\,\interp{e_2}$) and abstraction $\lambda x.e$
(encoded in LF as ${\sf lam}\,\lambda x. \interp{e}$). 

\subsection{Adequacy for LF and deductive terms}

\subsection{Adequacy for concurrent traces}


\section{The \sls~implementation}
\label{sec:prototype}

The prototype implementation of \sls~contains 
Following CLF and the Celf implementation, we write ${\ocircle}A$ in
Celf as \verb|{A}|. The mobile modality ${\gnab}A$ dowsn't have an
ASCII representation, so write \verb|$A| when $A$ is
mobile. Upshifts and downshifts are always inferred: this means that
we can't write down ${\uparrow}{\downarrow}A$ or
${\downarrow}{\uparrow}A$, but neither of these \ollll~propositions
are part of the \sls~fragment anyway.

Another change is for the sake of readability: if \verb|P| is a
positive atomic proposition, we can write \verb|!P| wherever \verb|P|
is expected. This allows us to write either \verb|a * b * c| or
\verb|a * $b * !c| in SLS to express the positive proposition ${\sf a}
\fuse {\sf b} \fuse {\sf c}$ where ${\sf a}$, ${\sf b}$, and ${\sf c}$
are ordered, linear, and persistent positive atomic propositions
(respectively).

\section{Logic programming interpretation}
\label{sec:framework-logicprog}

In Chapter 3 I call this distinction one between ``concurrent and deductive''
proofs, operationally it's the difference between forward chaining 
and backward chaining. Maintaining the distinction between these is why
we don't want the class $p^-_\mlax$ in the logic.

We have talked about {\it concurrent} and {\it deductive} proof
objects, and also about the intuitive notion of {\it concurrent
  computation} as the non-backtracking, forward-chaining 

(definitely discuss forward-chaining and backward-chaining as concepts)

Expand on literature review of quiescence from HOSC Section 4

Leave the question of quescense versus eagerly-trying-to-right-focus
versus saturation ambiguous. If you talk about pure saturation the
forward-reference Chapter 8. 

\subsection{Modes and well-moded specifications}
\label{sec:framework-modes}

