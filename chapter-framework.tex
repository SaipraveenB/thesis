\chapter{Substructural logical specifications}
\label{chapter-framework}

Logical framework time!

The proof term interpretation of focused sequent calculi is a term
representation called {\it spine form}. 
a

\section{Spine Form LF as a term language}

Other substructural logical frameworks, like Cervesato and Pfenning's
LLF \cite{cervesato02linear}, Polakow's OLF \cite{polakow01ordered},
and Watkins et al.'s CLF \cite{watkins02concurrent} are {\it
  fully-dependent type theories}: the language of terms, the domain of
first-order quantification, is the same as the language of proof
terms, the representatives of logical derivations (we will call the
domain of quantification the {\it object terms} when ``terms'' would
be ambiguous). The logical framework \sls~presented in this chapter
breaks from this tradition. The language of first-order
quantification, which was left unspecified in Chapter 3, will be
presently described as Spine Form LF, a well-understood logical
framework derived from the normal forms of the purely persistent type
theory LF \cite{harper93framework}.

All the information here is standard and adequately presented between
Harper, Honsell, and Plotkin's original presentation of LF
\cite{harper93framework}, Cervesato and Pfenning's discussion of spine
form terms \cite{cervesato02linear}, Watkins et al.'s presentation of
the canonical forms of CLF \cite{watkins02concurrent}, Harper and
Licata's discussion of Canonical LF \cite{harper07mechanizing}, and
Reed's spine form presentation of HLF \cite{reed09hybrid}. In
particular, our presentation attempts to mimics Harper and Licata's
presentation from \cite{harper07mechanizing}, except that we use a
spine form representation of terms. Canonical term languages
correspond to normal natural deduction proofs, whereas spine form term
languages correspond to focused sequent calculus proofs.

It would be entirely consistent for us to appropriate Harper and
Licata's Canonical LF presentation instead of presenting Spine Form
LF. Nevertheless, a spine-form presentation of canonical LF serves to
make our presentation more uniform, as spines are used in the proof
term language of \sls.


\subsection{Core syntax}

The syntax of Spine Form LF is extended in two places to handle \sls:
rules ${\sf r} : A^-$ in the signature contain negative \sls~types
$A^-$ (though it would be possible to separate out the LF portion of
signatures from the \sls~rules). % We also add four additional kinds,
% ${\sf prop}$, which classifies negative ordered atomic types $p^-$,
% ${\sf prop}\,{\sf ord}$, which classifies positive ordered atomic
% types $p^+$, ${\sf prop}\,{\sf lin}$, which classifies positive
% linear/mobile/ephemeral atomic types $p^+_\meph$, and ${\sf
%   prop}\,{\sf ord}$, which classifies positive persistent atomic types
% $p^+_\mpers$. 
% Other than the extra kinds classifying atomic \sls~propositions, kinds
% $\kappa$ are otherwise exactly as they are in other presentations of
% LF; kinds classify types $\tau$, and types $\tau$ classify normal
% terms $\lf{t}$ and spines $\lf{\spi}$. Kinds $\kappa$ and types $\tau$
% are both treated as syntactic refinements of {\it classifiers} $\nu$. 
\begin{align*}
& \mbox{Signatures} & \Sigma & ::= \cdot 
  \mid \Sigma, \lf{\sf c} : \tau
  \mid \Sigma, {\sf a} : \kappa
  \mid \Sigma, {\sf r} : A^-
\\
& \mbox{Variable contexts} & \Psi & ::= \cdot
  \mid \Psi, \lf{x} {:} \tau 
\\
& \mbox{Classifiers} & \nu & ::= \lfpi{x}{\nu}{\nu'} \mid {\sf type}
  \mid {\sf prop}
  \mid {\sf prop}\,{\sf ord}
  \mid {\sf prop}\,{\sf lin}
  \mid {\sf prop}\,{\sf pers}
  \mid \lfroot{\sf a}{\spi}
\\
& \mbox{Heads} & \lf{h} & ::= \lf{x} \mid \lf{\sf c}
\\
& \mbox{Normal terms} & \lf{t} & ::= \lf{\lambda x.t}
  \mid \lf{\lfroot{h}{\spi}}
\\
& \mbox{Spines} & \lf{\spi} & ::= \lf{t; \spi} \mid \lf{\lfnil}
\\
& \mbox{Substitutions} & \lf{\sigma} & ::= \lf{\cdot}
  \mid \lf{t/x, \sigma}
  \mid \lf{y/\!\!/x, \sigma}
\end{align*}

\noindent
Classifiers $\nu$ can be divided into three refinements.  Types $\tau$
are either function types $\lfpi{x}{\tau}{\tau'}$ or base types
$\lfroot{\sf a}{\spi}$.  Kinds $\kappa$ are either families
$\lfpi{x}{\tau}{\kappa}$ or one of the base kinds: ${\sf prop}$, ${\sf
  prop}\,{\sf ord}$, ${\sf prop}\,{\sf lin}$, or ${\sf prop}\,{\sf
  pers}$. Atomic classifiers $p$ have the form $\lfroot{\sf a}{\spi}$;
they can be atomic types of LF or atomic propositions of \sls.

LF spines $\lf\spi$ are just sequences of terms $\lf{(t_1; (\ldots;
  (t_n;())\ldots))}$; we will follow common convention and write
$\lf{h\,t_1\ldots t_n}$ as a convenient shorthand for the atomic term
$\lf{\lfroot{h}{(t_1; \ldots; (t_n;())\ldots)}}$; similarly, we will
write ${\sf a}\,\lf{t_1\ldots t_n}$ as a shorthand for atomic
classifiers $\lfroot{\sf a}{(t_1;
  (\ldots; (t_n;())\ldots))}$. % This shorthand evokes a canonical-forms
% presentation, as an atomic term, type, or proposition is a head
% $\lf{h}$ or ${\sf a}$ with the terms $\lf{t_1\ldots t_n}$ applied to
% it.

\subsection{Simple types and hereditary substitution}

In addition to LF types like $\lfpi{x}{(\lfpi{z}{(\lfroot{\sf
      a1}{\spi_1})}{\,(\lfroot{\sf
      a2}{\spi_2})})}{\,\lfpi{y}{(\lfroot{\sf
      a3}{\spi_3})}{\,(\lfroot{\sf a4}{\spi_4})}}$, both Canonical LF
and Spine Form LF take {\it simple types} into consideration. The
simple type corresponding to the type above is $({\sf a1} \supset {\sf
  a2}) \supset {\sf a3} \supset {\sf a4}$, where ${\supset}$
associates to the right. The simple type associated with
$\tau$ can is given by the function ${\mid}\tau{\mid}^- = \tau_s$, where
${\mid}\lfroot{\sf a}{\spi}{\mid}^- = {\sf a}$ and
${\mid}\lfpi{x}{\tau}{\tau'}{\mid}^- = {\mid}\tau{\mid}^- \supset
{\mid}\tau'{\mid}^-$. 


\begin{figure}
\begin{align*}
\fbox{$\lf{\sigma}(\lf{\spi})$}&
&
\fbox{$\lf{\sigma}(\lf{t'})$}
\\
\lf{\sigma}(\lf{t'; \spi}) 
 & = \lf{\no{\lf{\sigma}(\lf{t'})}; \no{\lf{\sigma}(\lf{\spi})}} &
\lf{\sigma}(\lf{\lambda y.t'}) 
 & = \lf{\lambda y.\,\no{\lf{(\sigma, y/\!\!/y)}(\lf{t'})}}
 & (\lf{y} \# \lf{\sigma})
\\
\lf{\sigma}\lfnil 
 & = \lfnil &
\lf{\sigma}(\lf{\lfroot{x}{\spi}}) 
 & = \subst{\lf t}{\no{\lf{\sigma}(\lf{\spi})}}
      & \lf{t/x} \in \lf{\sigma} 
\\
& &
\lf{\sigma}(\lf{\lfroot{x}{\spi}}) 
 & = \lf{\lfroot{y}{\no{\lf{\sigma}(\lf{\spi})}}} 
      & \lf{y/\!\!/x} \in \lf{\sigma} 
\\
& &
\lf{\sigma}(\lf{\lfroot{\sf c}{\spi}}) 
 & = \lf{\lfroot{\sf c}{\no{\lf{\sigma}(\lf{\spi})}}} 
\end{align*}\begin{align*}
\fbox{$[{\lf{t}}/{\lf{x}}]{\nu}$} &
\\
[\lf{t}/\lf{x}](\lfpi{y}{\nu}{\nu'})
 & = \lfpi{y}{[\lf{t}/\lf{x}]\nu}{[\lf{t}/\lf{x}]\nu'}
     \qquad (\lf x \neq \lf y) 
\\
[\lf{t}/\lf{x}]({\sf type})
  & = {\sf type}
\\ 
[\lf{t}/\lf{x}]({\sf prop}) 
 & = {\sf prop} 
\\
[\lf{t}/\lf{x}]({\sf prop}\,{\sf ord}) 
 & = {\sf prop}\,{\sf ord} 
\\
[\lf{t}/\lf{x}]({\sf prop}\,{\sf lin}) 
 & = {\sf prop}\,{\sf lin} 
\\
[\lf{t}/\lf{x}]({\sf prop}\,{\sf pers}) 
 & = {\sf prop}\,{\sf pers} 
\\
[\lf{t}/\lf{x}](\lfroot{\sf a}{\spi}) 
 & = \lfroot{\sf a}{\no{\rsubst{\lf{t}}{\lf{x}}{\lf{\spi}}}} 
\end{align*}
\caption{Simultaneous substitution on terms, spines, and classifiers}
\label{fig:simsubst}
\end{figure}

Variables and constants can be treated as having an intrinsic simple
type; these intrinsic simple types are sometimes written explicitly as
annotations $\lf{x}^{\tau_s}$ or $\lf{\sf c}^{\tau_s}$ (see, for
example, \cite{pfenning08church}), but we will leave them implicit.
An atomic term $\lf{h\,t_1\ldots t_n}$ must have an an simple atomic
type ${\sf a}$. This means that the head $\lf h$ must have simple type
$\tau_{s1} \supset \ldots \supset \tau_{sn} \supset {\sf a}$ and each
$\lf{t_i}$ much have simple type $\tau_{si}$. Similarly, a lambda term
$\lf{\lambda x. t}$ must have simple type $\tau_s \supset \tau_s'$
where $\lf x$ is a variable with simple type $\tau_s$ and $\lf t$ has
simple type $\tau_s'$.  

Simple types, which are treated with more care elsewhere care
elsewhere \cite{harper07mechanizing,reed09hybrid}, are critical
because they allow us to define hereditary substitution in
Figure~\ref{fig:lf-hsubst}. Spine Form LF terms correspond to the
proof terms for a focused presentation of minimal logic, and
hereditary substitution $\rsubst{\lf t}{\lf x}{\lf{t'}}$, which is
implicitly indexed by the simple type $\tau_s$ of $\lf t$ and $\lf x$,
is the computational content of cut admissibility on these proof
terms. 

\subsection{Judgments}

Hereditary substitution is necessary to define simultaneous
substitution into types and terms in Figure~\ref{fig:simsubst}. We treat
$[\lf{t}/\lf{x}]$ as a simultaneous substitution that acts as the
identity on all variables except for $\lf{x}$; this 
notation is used
in the definition of LF typing in in Figure~\ref{fig:lf-form}, which
is adapted to Spine Form LF from the Canonical LF presentation in
\cite{harper07mechanizing}. The judgments 
The
judgments $\lf{x}\#\lf{\sigma}$, $\lf{x}\#\Psi$, $\lf{\sf
  c}\#\Sigma$, ${\sf a}\#\Sigma$, and ${\sf r}\#\Sigma$ assert that
the relevant variable and constant does not already appear in the
context $\Psi$ (as a binding $\lf{x}{:}\tau$), the signature $\Sigma$
(as a declaration ($\lf{\sf c} : \tau$, ${\sf a} : \nu$, or 
${\sf r} : A^-$), or the substitution
$\lf{\sigma}$ (as a binding $\lf{t/x}$ or \mbox{$\lf{y/\!\!/x}$}). 

\begin{figure}
\fbox{$\vdash_\subord \Sigma\,{\sf sig}$}\vspace{-10pt}
\[
\infer
{\vdash_\subord \cdot\,{\sf sig} \mathstrut}
{}
\quad
\infer
{\vdash_\subord (\Sigma, \lf{\sf c} : \tau)\,{\sf sig} \mathstrut}
{\vdash_\subord \Sigma\,{\sf sig} 
 &
 \cdot \vdash_{\Sigma,\subord} \tau\,{\sf type}
 &
 \tau \prec_\subord \tau
 &
 \lf{\sf c} \# \Sigma \mathstrut}
\]
\[
\infer
{\vdash_\subord (\Sigma, {\sf a} : \kappa)\,{\sf sig} \mathstrut}
{\vdash_\subord \Sigma\,{\sf sig}
 &
 \vdash_{\Sigma, \subord} \kappa \,{\sf kind}
 &
 {\sf a} \sqsubset_\subord \kappa 
 &
 {\sf a} \# \Sigma\mathstrut}
\quad
\infer
{\vdash_\subord (\Sigma, {\sf r} : A^-)\,{\sf sig} \mathstrut}
{\vdash_\subord \Sigma\,{\sf sig}
 &
 \vdash_{\Sigma, \subord} A^- \,{\sf prop}^-
 &
 {\sf r} \# \Sigma \mathstrut}
\]

\medskip
\fbox{$\vdash_{\Sigma,\subord} \Psi\,{\sf ctx}$} -- presumes
  $\vdash_{\subord} \Sigma\,{\sf sig}$\vspace{-10pt}
\[
\infer
{\vdash_{\Sigma,\subord} \cdot\,{\sf ctx} \mathstrut}
{}
\quad
\infer
{\vdash_{\Sigma,\subord} (\Psi, \lf{x}{:}\tau)\,{\sf ctx} \mathstrut}
{\vdash_{\Sigma,\subord} \Psi\,{\sf ctx}
 &
 \Psi \vdash_{\Sigma, \subord} \tau\,{\sf type}
 &
 x \# \Psi}
\]

\medskip
\fbox{$\Psi \vdash_{\Sigma,\subord} \kappa\,{\sf kind}$} -- presumes
  $\vdash_{\Sigma, \subord} \Psi\,{\sf ctx}$
\[
\infer
{\Psi \vdash_{\Sigma,\subord} (\lfpi{x}{\tau}{\kappa})\,{\sf kind} \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \tau\,{\sf type}
 &
 \Psi, \lf{x}{:}\tau \vdash_{\Sigma,\subord} \kappa\,{\sf kind}}
\quad
\infer{\Psi \vdash_{\Sigma,\subord} {\sf type}\,{\sf kind} \mathstrut}{}
\quad
\infer{\Psi \vdash_{\Sigma,\subord} {\sf prop}\,{\sf kind} \mathstrut}{}
\]
\[
\infer
{\Psi \vdash_{\Sigma,\subord} ({\sf prop}\,{\sf ord})\,{\sf kind}\mathstrut}{}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} ({\sf prop}\,{\sf lin})\,{\sf kind}\mathstrut}{}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} ({\sf prop}\,{\sf pers})\,{\sf kind}\mathstrut}{}
\]

\medskip
\fbox{$\Psi \vdash_{\Sigma,\subord} \tau\,{\sf type}$} -- presumes
  $\vdash_{\Sigma, \subord} \Psi\,{\sf ctx}$
\[
\infer
{\Psi \vdash_{\Sigma,\subord}(\lfpi{x}{\tau}{\tau'})\,{\sf type} \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \tau\,{\sf type}
 &
 \Psi, \lf{x}{:}\tau \vdash_{\Sigma,\subord} \tau'\,{\sf type}
 &
 \tau \preceq_\subord \tau' \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord}(\lfroot{\sf a}{\spi})\,{\sf type} \mathstrut}
{a{:}\kappa \in \Sigma
 &
 \Psi, [\kappa] \vdash_{\Sigma,\subord} \lf{\spi} : {\sf type}
 \mathstrut}
\]

\medskip
\fbox{$\Psi \vdash_{\Sigma,\subord} t : \tau$} -- presumes 
  $\Psi \vdash_{\Sigma,\subord} \tau\,{\sf type}$
\[
\infer
{\Psi \vdash_{\Sigma,\subord} \lf{\lambda x.t} : \lfpi{x}{\tau}{\tau'}\mathstrut}
{\Psi, \lf{x}{:}\tau \vdash_{\Sigma,\subord} \lf{t} : \tau'\mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} \lf{\lfroot{\sf c}{\spi}} : \lfroot{\sf a}{\spi'}
 \mathstrut}
{\lf{\sf c} : \tau \in {\Sigma}
 &
 \Psi; [\tau] \vdash_{\Sigma,\subord} \spi : \tau'
 &
 \tau' = \lfroot{\sf a}{\spi'}\mathstrut}
\]
\[
\infer
{\Psi \vdash_{\Sigma,\subord} \lf{\lfroot{x}{\spi}} : \lfroot{\sf a}{\spi'}
 \mathstrut}
{\lf{x} {:} \tau \in {\Psi}
 &
 \Psi; [\tau] \vdash_{\Sigma,\subord} \spi : \tau'
 &
 \tau' = \lfroot{\sf a}{\spi'}\mathstrut}
\]

\medskip
\fbox{$\Psi, [\nu] \vdash_{\Sigma,\subord} \lf{\spi} : \nu_0$} --
presumes that either $\Psi \vdash_{\Sigma,\subord} \nu\, {\sf type}$
or that $\Psi \vdash_{\Sigma,\subord} \nu\, {\sf kind}$
\[
\infer
{\Psi, [\nu] \vdash_{\Sigma,\subord} \lfnil : \nu \mathstrut}
{}
\quad
\infer
{\Psi, [\lfpi{x}{\tau}{\nu}] \vdash_{\Sigma,\subord} \lf{t; \spi} : \nu_0
 \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \lf{t} : \tau
 &
 \lf{[t/x]}\nu = \nu'
 &
 \Psi, [\nu'] \vdash_{\Sigma,\subord} \lf{\spi} : \nu_0 \mathstrut}
\]

\medskip
\fbox{$\Psi \vdash \lf{\sigma} : \Psi'$} -- presumes
 $\vdash_{\Sigma,\subord} \Psi\,{\sf ctx}$
 and
 $\vdash_{\Sigma,\subord} \Psi'\,{\sf ctx}$
\[
\infer
{\Psi \vdash_{\Sigma,\subord} \cdot : \cdot \mathstrut}
{}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} (\lf{\sigma, t/x}) : \Psi', \lf{x}{:}\tau
  \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \lf{t} : \lf{\sigma}\tau 
 &
 \Psi \vdash_{\Sigma,\subord} \lf{\sigma} : \Psi' 
  \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} (\lf{\sigma, y/\!\!/x}) : \Psi', \lf{x}{:}\tau
  \mathstrut}
{\lf{y}{:}\lf{\sigma}\tau \in \Psi
 &
 \Psi \vdash_{\Sigma,\subord} \lf{\sigma} : \Psi'}
\]

\caption{LF formation judgments.}
\label{fig:lf-form}
\end{figure}

All the judgments in Figure~\ref{fig:lf-form} are indexed by a
transitive {\it subordination relation} $\subord$, similar to the one
introduced by Virga in \cite{virga99higherorder}. We treat $\subord$
as a binary relation on type family constants.  Let ${\sf head}(\tau)
= {\sf a}$ if $\tau =
\lfpi{x_1}{\tau_{1}}{\,.\,.\lfpi{x_{m}}{\tau_{m}}{\,\lfroot{\sf
      a}{\spi}}}$. The signature formation operations depend on two
judgments. The first, ${\sf a} \sqsubset_\subord \kappa$, relates type
family constants to types. It is always the case that $\kappa =
\lfpi{x_1}{\tau_1}{\ldots\lfpi{x_n}{\tau_n}{\sf type}}$.  The judgment
${\sf a} \sqsubset_\subord \kappa$ holds if $({\sf head}(\tau_i), {\sf
  a}) \in \subord$ for $1 \leq i \leq n$. The second judgment used in
signature formation, $\tau \prec \tau'$, holds if $({\sf head}(\tau),
{\sf head}(\tau')) \in \subord$, and the judgment $\tau \preceq \tau'$
used in type formation is the transitive closure of this relation.

There are a number of well-formedness theorems that we need to
consider, such as the fact that substitutions compose in a
well-behaved way and that hereditary substitution is always
well-typed.  However, as these theorems are adequately covered
elsewhere, we will proceed with using LF as a term language and will 
treat term-level operations like substitution somewhat informally.

\subsection{Adequacy}

{\it Adequacy} was the name given by Harper, Honsell, and Plotkin to the
methodology of connecting the inductive definitions we write in paper
to the canonical forms of a particular type family in LF. Consider,
as a standard example, the untyped lambda calculus, which is generally
specified by a BNF grammar such as the following:
\[
\obj{e} ::= \obj{x} \mid \obj{\lambda x.e} \mid \obj{e_1\,e_2}
\]
We can adequately encode this language of terms into LF (with a
subordination relation $\subord$ such that $({\sf exp}, {\sf
  exp}) \in \subord$) by giving the following signature:
\begin{align*}
\Sigma & = \cdot, 
\\
 & ~\quad {\sf exp} : {\sf type}, 
\\
 & ~\quad \lf{\sf app} : 
     \lfpi{x_1}{{\sf exp}}{\,\lfpi{x_2}{\sf exp}{\,\sf exp}},
\\
 & ~\quad \lf{\sf lam} : 
     \lfpi{x_1}{(\lfpi{x_2}{\sf exp}{\,\sf exp})}{\,\sf exp}
\end{align*}
Note that the variables $\lf{x_1}$ and $\lf{x_2}$ are bound by
$\Pi$-binders in the declaration of ${\sf app}$ and ${\sf lam}$ but
never used. The usual convention is to abbreviate
$\lfpi{x}{\tau}{\tau'}$ as $\tau \rightarrow \tau'$ when $\lf{x}$ is
not free in $\tau'$, which would give $\lf{\sf app}$ type ${\sf exp}
\rightarrow {\sf exp} \rightarrow {\sf exp}$ and $\lf{\sf lam}$ type
$({\sf exp} \rightarrow {\sf exp}) \rightarrow {\sf exp}$.

\bigskip
\begin{theorem}[Adequacy for terms]
  Up to standard $\alpha$-equivalence, there is a bijection between
  expressions $\obj{e}$ (with free variables in the set
  $\{\obj{x_1},\ldots,\obj{x_n}\}$) and Spine Form LF terms $\lf{t}$ such
  that $\lf{x_1}: \mathsf{exp}, \ldots, \lf{x_n}:\mathsf{exp} \vdash
  \lf{t} : \mathsf{exp}$. 
\end{theorem}

\begin{proof}
By induction on the structure of the inductive definition of $\obj{e}$
in the forward direction and by induction on the structure of 
terms $\lf{t}$ with type ${\sf exp}$ in the reverse direction.
\end{proof}

We express the constructive content of this theorem as a bijective
function $\interp{e} = \lf{t}$ from object language terms $\obj{e}$ to
representations LF terms $\lf{t}$ of type ${\sf exp}$. If we had also
defined substitution $\obj{[e/x]e'}$ on terms, it would be necessary
to show that the bijection is compositional: that is, that
$[\interp{e}/\lf{x}]\interp{e'} = \interp{[e/x]e'}$.  Note that
adequacy critically depends on the context having the form
$\lf{x_1}{:}{\sf exp},\ldots,\lf{x_n}{:}{\sf exp}$. If we had a
context with a variable $\lf{y}{:}({\sf exp} \rightarrow {\sf exp})$,
then we could form a term $\lf{y\,({\sf lam}\,\lambda x. x)}$ with
type ${\sf exp}$ that does {\it not} adequately encode any term
$\obj{e}$ in the untyped lambda calculus.

One of the reasons subordination is important in practice is that it
allows us to consider the adequate encoding of expressions in contexts
$\Psi$ that have other variables $\lf{x}{:}\tau$ as long as $({\sf
  head}(\tau),{\sf exp}) \notin \subord$. If $\Psi,\lf{x}{:}\tau
\vdash_{\Sigma,\subord} \lf{t} : {\sf exp}$ and $\tau
\not\preceq_\subord {\sf exp}$, then $\lf{x}$ cannot be free in
$\lf{t}$, so $\Psi \vdash_{\Sigma,\subord} \lf{t} : {\sf exp}$ holds as
well. By iterating this procedure, it may be possible to strengthen a
context $\Psi$ into one of the form $\lf{x_1}{:}{\sf
  exp},\ldots,\lf{x_n}{:}{\sf exp}$, in which case we can conclude
that $\lf t = \interp{e}$ for some untyped lambda calculus term $\obj
e$.

\begin{figure}[t]
\fbox{$\Psi \vdash_{\Sigma,\subord} A^+\,{\sf prop}^+$} -- presumes
  $\vdash_{\Sigma,\subord} \Psi\,{\sf ctx}$
\[
\infer
{\Psi \vdash_{\Sigma,\subord} \lfroot{\sf a}{\spi}\,{\sf prop}^+ \mathstrut}
{{\sf a}{:}\kappa \in \Sigma
 &
 \Psi, [\kappa] \vdash_{\Sigma,\subord} \lf{\spi} : {\sf prop}\,{\sf ord} \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} \lfroot{\sf a}{\spi}\,{\sf prop}^+ \mathstrut}
{{\sf a}{:}\kappa \in \Sigma
 &
 \Psi, [\kappa] \vdash_{\Sigma,\subord} \lf{\spi} : {\sf prop}\,{\sf lin} \mathstrut}
\]
\[
\infer
{\Psi \vdash_{\Sigma,\subord} \lfroot{\sf a}{\spi}\,{\sf prop}^+ \mathstrut}
{{\sf a}{:}\kappa \in \Sigma
 &
 \Psi, [\kappa] \vdash_{\Sigma,\subord} \lf{\spi} : {\sf prop}\,{\sf pers} \mathstrut}
\]
\[
\infer
{\Psi \vdash_{\Sigma,\subord} {\downarrow}A^-\,{\sf prop}^+ \mathstrut}
{\Psi \vdash_{\Sigma,\subord} A^-\,{\sf prop}^- \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} {\gnab}A^-\,{\sf prop}^+ \mathstrut}
{\Psi \vdash_{\Sigma,\subord} A^-\,{\sf prop}^- \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} {!}A^-\,{\sf prop}^+ \mathstrut}
{\Psi \vdash_{\Sigma,\subord} A^-\,{\sf prop}^- \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} \one\,{\sf prop}^+ \mathstrut}
{}
\] 
\[
\infer[*]
{\Psi \vdash_{\Sigma,\subord} A^+ \fuse B^+\,{\sf prop}^+ \mathstrut}
{\Psi \vdash_{\Sigma,\subord} A^+\,{\sf prop}^+ 
 &
 \Psi \vdash_{\Sigma,\subord} B^+\,{\sf prop}^+  \mathstrut}
\quad
\infer[*]
{\Psi \vdash_{\Sigma,\subord} \exists \lf{x}{:}\tau. A^+\,{\sf prop}^+ \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \tau\,{\sf type}
 &
 \Psi, \lf{x}{:}\tau \vdash_{\Sigma,\subord} A^+\,{\sf prop}^+ \mathstrut}
\] 
\[
\infer[*]
{\Psi \vdash_{\Sigma,\subord} \lf{t} \doteq_\tau \lf{s}\,{\sf type}}
{\Psi \vdash_{\Sigma,\subord} \tau\,{\sf type}
 &
 \Psi \vdash_{\Sigma,\subord} \lf{t} : \tau
 &
 \Psi \vdash_{\Sigma,\subord} \lf{s} : \tau}
\]

\medskip
\fbox{$\Psi \vdash_{\Sigma,\subord} A^-\,{\sf prop}^-$} -- presumes
  $\vdash_{\Sigma,\subord} \Psi\,{\sf ctx}$
\[
\infer
{\Psi \vdash_{\Sigma,\subord} \lfroot{\sf a}{\spi}\,{\sf prop}^- \mathstrut}
{{\sf a}{:}\kappa \in \Sigma
 &
 \Psi, [\kappa] \vdash_{\Sigma,\subord} \lf{\spi} : {\sf prop} \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} {\ocircle}A^+\,{\sf prop}^- \mathstrut}
{\Psi \vdash_{\Sigma,\subord} A^+ : {\sf prop}^+ \mathstrut}
\]
\[
\infer
{\Psi \vdash_{\Sigma,\subord} A^+ \lefti B^-\,{\sf prop}^- \mathstrut}
{\Psi \vdash_{\Sigma,\subord} A^+\,{\sf prop}^+ 
 &
 \Psi \vdash_{\Sigma,\subord} B^-\,{\sf prop}^-  \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} A^+ \righti B^-\,{\sf prop}^- \mathstrut}
{\Psi \vdash_{\Sigma,\subord} A^+\,{\sf prop}^+ 
 &
 \Psi \vdash_{\Sigma,\subord} B^-\,{\sf prop}^-  \mathstrut}
\] 
\[
\infer
{\Psi \vdash_{\Sigma,\subord} A^- \with B^-\,{\sf prop}^- \mathstrut}
{\Psi \vdash_{\Sigma,\subord} A^-\,{\sf prop}^- 
 &
 \Psi \vdash_{\Sigma,\subord} B^-\,{\sf prop}^-  \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} \forall \lf{x}{:}\tau. A^-\,{\sf prop}^- \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \tau\,{\sf type}
 &
 \Psi, \lf{x}{:}\tau \vdash_{\Sigma,\subord} A^-\,{\sf prop}^- \mathstrut}
\] 
\caption{\sls~proposition formation judgments}
\label{fig:sls-propform}
\end{figure}


\section{The logical framework \sls}

In this section, we will describe a restricted set of polarized
\ollll~propositions and focused \ollll~proof terms that make up the
logical framework \sls. For the remainder of the thesis, we will work
exclusively with the following positive and negative
\sls~propositions, which are a syntactic refinement of the positive
and negative propositions of polarized \ollll:
\begin{align*}
A^+, B^+, C^+ & ::= p^+ \mid p^+_\meph \mid p^+_\mpers \mid {\downarrow}A^-
  \mid {\gnab}A^- \mid {!}A^- \mid \one \mid A^+ \fuse B^+
  \mid \exists \lf{x}{:}\tau.A^+ \mid \lf{t} \doteq_\tau \lf{s}
\\
A^-, B^-, C^- & ::= p^- \mid {\ocircle}A^+ \mid A^+ \lefti B^- 
  \mid A^+ \righti B^- \mid A^- \with B^-
  \mid \forall \lf{x}{:}\tau.A^-
\end{align*}
%Aside from the type annotation $\tau$ on unification $\lf{t}
%\doteq_\tau \lf{s}$ and on the quantifiers $\forall \lf{x}{:}\tau. A^-$
%and $\exists \lf{x}{:}\tau. A^+$, which we will in general leave implicit,
%this is exactly a refinement of the  
%Notably missing from this refinement are
%upshifts ${\uparrow}A^+$ and right-permeable atomic propositions
%$p^-_\mlax$.
The formation judgments for \sls~types are given in
Figure~\ref{fig:sls-propform}, and these are used to specify the
formation of stable, inverting, and in-focus \sls~contexts in
Figure~\ref{fig:sls-ctxform}. This restrictions we make to contexts
justify our continued practice of omitting the $\mtrue$ annotation
when talking about inverting positive propostiions $A^+$ or focused
negative propositions $[A^-]$ in the context. We will also continue to
avoid using variable names $x$ with inverting positive propostiions
and focused negative propositions. In the case of focused
propositions, there is a straightforward justification: the form of
context ensures there is at most one of them. In the case of positive
propositions, we are justified by the convention discussed in the last
chapter that we only ever frame off the leftmost positive proposition
in the context.

Positive ordered atomic propositions
$p^+$ are atomic classifiers ${\sf a}\,\lf{t_1}\ldots\lf{t_n}$ with
kind ${\sf prop}\,{\sf ord}$, positive linear atomic propositions
$p^+_\meph$ and $p^+_\mpers$ are (respectively) atomic classifiers
with kind ${\sf prop}\,{\sf lin}$ and ${\sf prop}\,{\sf pers}$, and
negative ordered atomic propositions $p^-$ are atomic classifiers
with kind ${\sf prop}$.  From this point on,
we will unambiguously refer to atomic propositions $p^-$ as negative
atomic propositions, omitting ``ordered.'' Similarly, we will refer to
atomic propositions $p^+$, $p^+_\meph$, and $p^+_\mpers$ collectively
as positive atomic propositions but individually as ordered, linear,
and persistent propositions, respectively, omitting ``positive.''
(``Mobile'' and ``ephemeral'' will continue to be used as synonyms for
``linear.'')

\begin{figure}[t]
\fbox{$\Psi \vdash_{\Sigma,\subord} T\,{\sf left} \mathstrut$} -- presumes
  $\vdash_{\Sigma,\subord} \Psi\,{\sf ctx}$
\[
\infer
{\Psi \vdash_{\Sigma,\subord} (\islvl{A^-})\,{\sf left} \mathstrut}
{\Psi \vdash_{\Sigma,\subord} A^-\,{\sf prop}^- \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} 
   (\istrue{\susp{\lfroot{\sf a}{\spi}}})\,{\sf left} \mathstrut}
{{\sf a} : \kappa \in \Sigma
 & 
 \Psi, [\kappa] \vdash_{\Sigma,\subord} \lf{\spi} : {\sf prop}\,{\sf ord}
 \mathstrut}
\]
\[
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} 
   (\iseph{\susp{\lfroot{\sf a}{\spi}}})\,{\sf left} \mathstrut}
{{\sf a} : \kappa \in \Sigma
 & 
 \Psi, [\kappa] \vdash_{\Sigma,\subord} \lf{\spi} : {\sf prop}\,{\sf lin}
 \mathstrut}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} 
   (\ispers{\susp{\lfroot{\sf a}{\spi}}})\,{\sf left} \mathstrut}
{{\sf a} : \kappa \in \Sigma
 & 
 \Psi, [\kappa] \vdash_{\Sigma,\subord} \lf{\spi} : {\sf prop}\,{\sf pers}
 \mathstrut}
\]

\medskip
\fbox{$\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf stable} \mathstrut$} -- presumes
  $\vdash_{\Sigma,\subord} \Psi\,{\sf ctx}$
\[
\infer
{\Psi \vdash_{\Sigma,\subord} \cdot\,{\sf stable} \mathstrut}
{}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} (\Delta, x{:}T)\,{\sf stable} \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf stable}
 &
 \Psi \vdash_{\Sigma,\subord} T\,{\sf left}}
\]

\medskip
\fbox{$\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf inv} \mathstrut$} -- presumes
  $\vdash_{\Sigma,\subord} \Psi\,{\sf ctx}$
\[
\infer
{\Psi \vdash_{\Sigma,\subord} \cdot\,{\sf inv} \mathstrut}
{}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} (\Delta, x{:}T)\,{\sf inv} \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf inv}
 &
 \Psi \vdash_{\Sigma,\subord} T\,{\sf left}}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} (\Delta, x{:}\istrue{A^+})\,{\sf inv} \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf inv}
 &
 \Psi \vdash_{\Sigma,\subord} A^+\,{\sf prop}^+}
\]

\medskip
\fbox{$\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf infoc} \mathstrut$} -- presumes
  $\vdash_{\Sigma,\subord} \Psi\,{\sf ctx}$
\[
\infer
{\Psi \vdash_{\Sigma,\subord} \cdot\,{\sf infoc} \mathstrut}
{}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} (\Delta, x{:}T)\,{\sf infoc} \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf infoc}
 &
 \Psi \vdash_{\Sigma,\subord} T\,{\sf left}}
\quad
\infer
{\Psi \vdash_{\Sigma,\subord} (\Delta, x{:}\istrue{[A^-]})\,{\sf infoc} 
 \mathstrut}
{\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf stable}
 &
 \Psi \vdash_{\Sigma,\subord} A^-\,{\sf prop}^-}
\]
\caption{\sls~context formation judgments}
\label{fig:sls-ctxform}
\end{figure}

The atomic propositions $\zero$ and $A^+ \oplus B^+$ were excluded
from \sls~because our development of patterns, steps, and traces
requires that all left rules for positive propositions have exactly
one premise: ${\zero}_L$ has zero premises and ${\oplus}_L$ has
two. With the elimination of these propositions, the only rule that
does not always have one premise is the left rule for unification,
where the higher-order premise represents a potentially infinite
number of premises:
\[
\infer[{\doteq}_L]
{\foc{\Psi}{\frameoff{\Theta}{\lf{t} \doteq \lf{s}}}{U}}
{\forall(\Psi' \vdash \lf{\sigma} : \Psi).
 &
 \lf{\sigma t} = \lf{\sigma s}
 &
 \longrightarrow
 &
 \foc{\Psi'}{\tackon{\lf{\sigma}\Theta}{\cdot}}{\lf{\sigma} U}
 }
\]
Recall from our discussion of 
in Section~\ref{sec:firstorderlogic} that, when $\lf{t}$ and
$\lf{s}$ have a most general unifier, this rule is equivalent to the following
rule, which we can associate with the proof term $\sigma.N$:
\[
\infer[{\doteq}_L]
{\foc{\Psi}{\frameoff{\Theta}{\lf{t} \doteq \lf{s}}}{U}}
{\Psi' \vdash \lf{\sigma} : \Psi 
  ~ \mbox{is a most general unifier of $t$ and $s$}
 &
 \foc{\Psi'}{\tackon{\lf{\sigma}\Theta}{\cdot}}{\lf{\sigma} U}}
\]
The pattern fragment of higher-order logic defines a syntactic
criteria under which unification problems either have no solution or a
single, most general solution \cite{miller91unification}. This is not
enough for our purposes, because we need ${\doteq}_L$ to always have
exactly one premise. We therefore must restrict the structure of terms
so that there is always a one most general unifier.

The requirement that unification always have one most general solution
is managed by placing an extra restriction on the $\forall$, 
$\exists$, and $\doteq$ formation rules, indicated by asterisks in
Figure~\ref{fig:sls-propform}. We will restrict unification to 
base LF types, and treat unification as well-formed only when one 
of two conditions hold:
\smallskip
\begin{enumerate}
\item Unification at an atomic type $p$ that is {\it not
subordinate to itself} ($p \not\prec_\subord p$) is always allowed. 
Types that are not self-subordinate to themselves can only be inhabited
by variables: that is, if $p \not\prec_\subord p$ and 
$\Psi \vdash_{\Sigma,\subord} \lf{t} : p$, then $\lf{t} = \lf{{a}}$
where $\lf{a}:p \in \Psi$. For any such unification problem 
$\lf{{a}} \doteq \lf{{b}}$, both 
$\lf{[{a}/b]}$ and $\lf{[{b}/a]}$ are most
general unifiers.
\item Every variable bound by an existential quantifier 
$\exists \lf{x}{:}p.\,A^+$ or a universal quantifier 
$\forall \lf{x}{:}p.\,A^-$ can be associated with at most one 
proposition $\lf{x} \doteq \lf{t}$, where $\lf{t}$ is an arbitrary 
term that appears in the same focusing
phase\footnote{This is what Andreoli calls a {\it monopole}.} 
as the quantifier. 
The proposition 
$\forall \lf{x}.\, 
 \forall \lf{y}.\, {\downarrow}({\sf p}\,\lf{x}) 
   \lefti \lf{x} \doteq \lf{y} 
   \lefti {\sf p}\,\lf{y}$ satisfies this condition but
$\forall \lf{x}.\,\forall \lf{y}.\,{\ocircle}(\lf{x} \doteq \lf{y})$ does not 
($\ocircle$ breaks focus), and the proposition 
${\ocircle}(\exists \lf{x}. \lf{x} \doteq \lf{t})$ satisfies this condition
but
${\ocircle}(\exists \lf{x}. 
  {\uparrow}(\lf{x} \doteq \lf{t} \lefti {\sf p}\,\lf{x}))$
does not (${\uparrow}$ breaks focus).
The proposition
${\ocircle}(\exists \lf{x}.\, 
\lf{x} \doteq \lf{t} \fuse \lf{x} \doteq \lf{t})$ 
does not satisfy this condition because the introduced variable $\lf{x}$ is 
associated with two different unifications. 

This restriction ensures that, if
the unification appears on the left, the left-hand side of the unification
will always be a variable
$\lf{x}$, meaning that $\lf{[t/x]}$ is always a most general unifier.
This usage of unification is essentially just a notational
definition \cite{pfenning99algorithms}.
\end{enumerate}
\smallskip

Notably missing from the \sls~types are the upshift ${\uparrow}A^+$
and right-permeable negative atomic propositions $p^-_\mlax$. The
removal of these to propositions effectively means that the succedent
of a stable \sls~sequent can only be $\istrue{\susp{p^-}}$ or
$\islax{A^+}$. Sequents that establish the truth of suspended negative
propositions are the basis of {\it deductive} proof terms, and
sequents that establish the lax truth of a positive proposition are
the basis of {\it concurrent} proof terms. 

We could stop here and use the refinement of \ollll~proof terms that
corresponds to our refinement of propositions as the language of
\sls~proof terms. This would be entirely sufficient for the way we
intend to use deductive proof terms, but for two reasons it would be
less than ideal for our discussion of concurrent proof terms. First,
the proof terms of focused \ollll~make it inconvenient (though not
impossible) to talk about concurrent equality
(Section~\ref{sec:framework-concurrenteq}). Second, one of our primary
uses of \sls~in this thesis will be to talk about {\it traces}, which
correspond roughly to partial proofs
\[
\deduce
{\foc{\Psi}{\Delta}{\islax{A^+}}\mathstrut}
{\deduce{\vdots\mathstrut}
  {\vspace{-4pt}\foc{\Psi'}{\Delta'}{\islax{A^+}}}}
\]
in \ollll, where both the top and bottom sequents are stable and where
$A^+$ is some unspecified, parametric positive proposition. Using
\ollll-derived proof terms makes it difficult to talk about about and
manipulate proofs of this form.

In the remainder of this section, we will present a proof term
assignment for \sls~that facilitates discussing concurrent equality
and partial proofs. \sls~proof terms are in bijective correspondence
with \ollll~proof terms when we consider complete (deductive) proofs,
but the introduction of patterns and traces changes the structure
of derivations and proof terms.

\subsection{Process states}

A {\it process state} is a disembodied left-hand side of a sequent that
we use to describe the intermediate states of concurrent systems. The 
goal of concurrent traces is to capture the structure of partial proofs
\[
\deduce
{\foc{\Psi}{\Delta}{\islax{A^+}}\mathstrut}
{\deduce{\vdots\mathstrut}
  {\vspace{-4pt}\foc{\Psi'}{\Delta'}{\islax{A^+}}}}
\]
where $A^+$ is a parametric conclusion as the relation between two 
process states. As a first cut, we can represent the initial state as 
$(\Psi; \Delta)$ and the final state as $(\Psi'; \Delta')$, and we can
omit $\Psi$ and just write $\Delta$ when that is sufficiently clear.

The first cut is not quite enough due to the presence of unification
in \sls~-- in paricular, the first use-case of unification where we
unify members of a type only inhabited by variables. Consider the
following partial proof:
\[
\deduce
{\foc{\lf{a}{:}p, \lf{b}{:}p}
  {x{:}{\ocircle}(\lf{a} \doteq \lf{b}), 
   z{:}\susp{{\sf foo}\,\lf{a}\,\lf{a}}}
  {\islax{({\sf foo}\,\lf{a}\,\lf{b})}}\mathstrut}
{\deduce{\vdots\mathstrut}
  {\vspace{-4pt}\foc{\lf{b}{:}p}
   {z{:}\susp{{\sf foo}\,\lf{b}\,\lf{b}}}
   {\islax{({\sf foo}\,\lf{b}\,\lf{b})}}}}
\]
This partial proof can be constructed in one focusing step by left
focusing on $x$. It is insufficient to capture the first process
state as 
$\left({\lf{a}{:}p, \lf{b}{:}p}; 
 {x{:}{\ocircle}(\lf{a} \doteq \lf{b}), 
  z{:}\susp{{\sf foo}\,\lf{a}\,\lf{a}}}\right)$
and the second process state as
$\left({\lf{b}{:}p};
 {z{:}\susp{{\sf foo}\,\lf{b}\,\lf{b}}}\right)$, as this would fail to 
capture that the suceedant $\islax{({\sf foo}\,\lf{b}\,\lf{b})}$
associated with the second process state is a substitution instance of
the succeedant
$\islax{({\sf foo}\,\lf{a}\,\lf{b})}$ associated with the first. In general,
if the overall proof proves some proposition $\islax{A^+}$, then 
the missing subproof has a succeedant $\islax{\lf{[b/a]}A^+}$.

A process state is therefore written as $(\Psi; \Delta)_{\lf{\sigma}}$ 
and is well-formed under
signature $\Sigma$ and subordination relation $\subord$ if 
$\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf stable}$ (which presumes that
$\vdash_{\Sigma,\subord} \Psi\,{\sf sctx}$) and if 
$\Psi \vdash \lf{\sigma} : \Psi_0$, where $\Psi_0$ is some unspecified third 
context that represents a starting point. 
\[
\infer
{\vdash_{\Sigma,\subord} (\Psi; \Delta)_{\lf{\sigma}}\,{\sf state}
 \mathstrut}
{\vdash_{\Sigma,\subord} \Psi : {\sf ctx}
 &
 \Psi \vdash_{\Sigma,\subord} \Delta\,{\sf inv}
 &
 \vdash_{\Sigma,\subord} \Psi_0 : {\sf ctx}
 &
 \Psi \vdash \lf{\sigma} : \Psi_0
 \mathstrut}
\]
Taking $\Psi_0 = \lf{a}{:}p, \lf{b}{:}p$, the partial proof above can
thus be represented as a step between these two process states:
\[
\left({\lf{a}{:}p, \lf{b}{:}p}; 
 {x{:}{\ocircle}(\lf{a} \doteq \lf{b}), 
  z{:}\susp{{\sf foo}\,\lf{a}\,\lf{a}}}\right)_{\lf{(a/a,\,b/b)}}
\leadsto_{\Sigma,\subord}
\left({\lf{b}{:}p};
 {z{:}\susp{{\sf foo}\,\lf{b}\,\lf{b}}}\right)_{\lf{(b/a,\,b/b)}}
\]
Steps will be given proof terms in Section~\ref{sec:framework-concurrent}.

%In almost all cases, the substitution $\lf\sigma$ associated with a process
%state is the identity and will be omitted, and the LF context $\Psi$
%will frequently be omitted as well. 

\begin{figure}
\fbox{$P :: (\Psi; \Delta)_{\lf{\sigma}}
         \Longrightarrow_{\Sigma,\subord}
           (\Psi'; \Delta')_{\lf{\sigma}}$}
 -- presumes
 $\vdash_{\Sigma,\subord} (\Psi; \Delta)_{\lf{\sigma}}\,{\sf state}$
\[
\infer[()]
{() :: (\Psi; \Delta)_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord} 
       (\Psi; \Delta)_{\lf{\sigma}}}
{\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf stable}}
\]
\[
\infer[\eta^+]
{z,P :: (\Psi; \frameoff{\Theta}{p^+_\mlvl})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord} 
        (\Psi'; \Delta')_{\lf{\sigma'}}}
{P :: (\Psi; \tackon{\Theta}{z{:}\islvl{\susp{p^+_\mlvl}}})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
\quad
\infer[{\downarrow}_L]
{x,P :: (\Psi; \frameoff{\Theta}{{\downarrow}A^-})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
{P :: (\Psi; \tackon{\Theta}{x{:}\istrue{A^-}})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
\]
\[
\infer[{\gnab}_L]
{x,P :: (\Psi; \frameoff{\Theta}{{\gnab}A^-})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
{P :: (\Psi; \tackon{\Theta}{x{:}\iseph{A^-}})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
\quad
\infer[{\bang}_L]
{x,P :: (\Psi; \frameoff{\Theta}{{!}A^-})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
{P :: (\Psi; \tackon{\Theta}{x{:}\ispers{A^-}})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
\]
\[
\infer[{\one}_L]
{P :: (\Psi; \frameoff{\Theta}{\one})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
{P :: (\Psi; \tackon{\Theta}{\cdot})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
\quad 
\infer[{\fuse}_L]
{P :: (\Psi; \frameoff{\Theta}{A^+ \fuse B^+})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
{P :: (\Psi; \tackon{\Theta}{\mkconj{A^+}{B^+}})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
\]
\[
\infer[{\exists}_L]
{\lf{a},P :: (\Psi; \frameoff{\Theta}{\exists \lf{a}{:}\tau. A^+})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
{P :: (\Psi, \lf{a}{:}\tau; \tackon{\Theta}{A^+})_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
\]
\[
\infer[{\doteq}_L]
{\lf{t/a},P :: 
  (\Psi, \lf{a}{:}\tau, \Psi'; \frameoff{\Theta}{\lf{a} \doteq \lf{t}}
   )_{\lf{\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
{P :: (\Psi, \lf{[t/a]}\Psi'; {\tackon{\lf{[t/a]}\Theta}{\cdot}}
       )_{\lf{[t/a]\sigma}}
           \Longrightarrow_{\Sigma,\subord}
        (\Psi'; \Delta')_{\lf{\sigma'}}}
\]
\caption{\sls~patterns}
\label{fig:sls-patterns}
\end{figure}


\subsection{Patterns}
\label{sec:framework-patterns}

Our restrictions on \sls~propositions give derivations the property
that every positive proposition has exactly one premise. A {\it
  pattern} is a syntactic entity that captures the linear structure of
left inversion on positive propositions. Instead of having a somewhat
inscrutable proof term of the form
${\tlaml{\texistsl{\lf{a}}
   {\tfusel{\tfusel{\tetap{x}{\tgnabl{y}{\tdownl{z}{N}}}}}}}}$,
for the proposition 
%
$(\exists \lf{a}.\,{\sf p}\,\lf{a} 
             \fuse {\gnab}A^-
             \fuse {\downarrow}B^-) \lefti C^-$
%
the \sls~proof term associated with this proposition, which uses patterns, is
$(\lambda \lf{a},x,y,z.\, N)$. The pattern $P = \lf{a}, x,y,z$ captures
the structure of left inversion on the positive proposition 
$\exists \lf{a}.\,{\sf p}\,\lf{a} 
             \fuse {\gnab}A^-
             \fuse {\downarrow}B^-$.

The grammar of patterns is simple.
% 
Inversion on positive propositions
can only have the effect of introducing new bindings (either LF
variables $\lf{a}$ or \sls~variables $x$) or handling a unification
$\lf{a} \doteq \lf{t}$, which by our discussion above can always be
resolved by the most general unifier $\lf{[t/a]}$, so the pattern associated
with a proposition $\lf{a} \doteq \lf{t}$ is $\lf{t/a}$. 
\[
P ::= () \mid x, P \mid \lf{a}, P \mid \lf{t/a}, P
\] 
For sequences with one or more elements, we omit the trailing
comma and $()$, writing $x, \ldots, z$ 
instead of $x, \ldots, z, ()$. 

\sls~patterns are associated with a decomposition relation on
\sls~process states: $P :: (\Psi; \Delta)_{\lf{\sigma}}
\Longrightarrow_{\Sigma,\subord} (\Psi'; \Delta')_{\lf{\sigma'}}$.
The typing rules for \sls~patterns are given in
Figure~\ref{fig:sls-patterns}. We preserve the side conditions from
the previous chapter: when we frame off a inverting positive
proposition in the process state, it is required to be the left-most
one. (The formation of contexts requires that inverting positive
propositions only appear as $\istrue{A^+}$, so if there are any inverting
positive propositions the left-most positive proposition is always
well-defined.)

There no longer appears to be a one-to-one correspondence between
proof terms and rules: ${\downarrow}_L$, ${\gnab}_L$, and ${!}_L$
appear to have the same proof term, and ${\one}_L$ and ${\fuse}_L$
appear to have no proof term at all. To view patterns as being
intrinsically typed -- that is, to view them as actual representatives
of derivations -- we must think of patterns as carrying extra
annotations that allow them to continue matching the structure of
proof rules.

\begin{figure}
\fbox{$\foctx{\Psi}{\Delta}{V}{[A^+]}$} -- presumes
  $\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf stable}$ and
  $\Psi \vdash_{\Sigma,\subord} A^+\,{\sf prop}^+$
\[
\infer[{\it id}^+]
{\foctx{\Psi}{z{:}\susp{A^+}}{z}{[A^+]}}
{}
\]
\[
\infer[{\downarrow}_R]
{\foctx{\Psi}{\Delta}{\tdownr{N}}{[{\downarrow}A^-]}}
{\foctx{\Psi}{\Delta}{N}{A^-}}
\quad
\infer[{\gnab}_R]
{\foctx{\Psi}{\restrictto{\Delta}{\meph}}{\tgnabr{N}}{[{\gnab}A^-]}}
{\foctx{\Psi}{\Delta}{N}{A^-}}
\quad
\infer[{!}_R]
{\foctx{\Psi}{\restrictto{\Delta}{\mpers}}{\tbangr{N}}{[{!}A^-]}}
{\foctx{\Psi}{\Delta}{N}{A^-}}
\]
\[
\infer[{\one}_R]
{\foctx{\Psi}{\cdot}{\toner}{[\one]}}
{}
\quad
\infer[{\fuse}_R]
{\foctx{\Psi}
  {\matchconj{\Delta_1}{\Delta_2}}{\tfuser{V_1}{V_2}}{[A^+_1 \fuse A^+_2]}}
{\foctx{\Psi}{\Delta_1}{V_1}{[A^+_1]}
 &
 \foctx{\Psi}{\Delta_2}{V_2}{[A^+_2]}}
\]
\[
\infer[{\exists}_R]
{\foctx{\Psi}{\Delta}{\texistsr{\lf{t}}{V}}{[\exists \lf{a}{:}\tau. A^+]}}
{\Psi; \Delta \vdash_{\Sigma,\subord} \lf{t} : \tau
 &
 \foctx{\Psi}{\Delta}{V}{[A^+]}}
\quad
\infer[{\doteq}_R]
{\foctx{\Psi}{\cdot}{\tunifr}{\lf{t} \doteq \lf{t}}}
{}
\]

\medskip
\fbox{$\foctx{\Psi}{\Delta}{N}{\istrue{A^-}}$} -- presumes
  $\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf stable}$ and
  $\Psi \vdash_{\Sigma,\subord} A^-\,{\sf prop}^-$
\[
\infer[{\it focus}_L]
{\foctx{\Psi}{\frameoff{\Theta}{x{:}A^-}}{\tfocusl{x}{\Sp}}{U}}
{\foctx{\Psi}{\tackon{\Theta}{[A^-]}}{\Sp}{U}}
\quad
\infer[{\it rule}]
{\foctx{\Psi}{\frameoff{\Theta}{\cdot}}{\tfocusl{\sf r}{\Sp}}{U}}
{{\sf r} : A^- \in \Sigma 
 &
 \foctx{\Psi}{\tackon{\Theta}{[A^-]}}{\Sp}{U}}
\]
\[
\infer[{\lefti}_R]
{\foctx{\Psi}{\Delta}{\lambda P.N}{A^+ \lefti B^-}}
{P :: (\Psi; \mkconj{A^+}{\Delta})_{\lf{\sf id}} 
  \Longrightarrow_{\Sigma,\subord}
 (\Psi';\Delta')_{\lf{\sigma'}}
 &
 \foctx{\Psi'}{\Delta'}{N}{\lf{\sigma'}B^-}}
\]
\[
\infer[{\righti}_R]
{\foctx{\Psi}{\Delta}{\lambda P.N}{A^+ \righti B^-}}
{P :: (\Psi; \mkconj{\Delta}{A^+})_{\lf{\sf id}} 
  \Longrightarrow_{\Sigma,\subord}
 (\Psi';\Delta')_{\lf{\sigma'}}
 &
 \foctx{\Psi'}{\Delta'}{N}{\lf{\sigma'}B^-}}
\]
\[
\infer[{\with}_R]
{\foctx{\Psi}{\Delta}{\twithr{N_1}{N_2}}{A_1^- \with A_2^-}}
{\foctx{\Psi}{\Delta}{N_1}{A_1^-}
 &
 \foctx{\Psi}{\Delta}{N_2}{A_2^-}}
\quad
\infer[{\forall}_R]
{\foctx{\Psi}{\Delta}{\tforallr{\lf{a}}{N}}{\forall \lf{a}{:}\tau. A^-}}
{\foctx{\Psi, \lf{a}{:}\tau}{\Delta}{N}{A^-}}
\]

\medskip
\fbox{$\foctx{\Psi}{\Delta}{\Sp}{U}$} --
  presumes
  $\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf infoc}$
\[
\infer[{\it id}^-]
{\foctx{\Psi}{{[A^-]}}{\tnil}{\istrue{\susp{A^-}}}}
{}
\]
\[
\infer[{\lefti}_L]
{\foctx{\Psi}{\frameoff{\Theta}{\matchconj{\Delta}{[A^+ \lefti B^-]}}}
  {V; \Sp}{U}}
{\foctx{\Psi}{\Delta}{V}{[A^+]}
 &
 \foctx{\Psi}{\tackon{\Theta}{[B^-]}}{\Sp}{U}}
\]
\[
\infer[{\righti}_L]
{\foctx{\Psi}{\frameoff{\Theta}{\matchconj{[A^+ \righti B^-]}{\Delta}}}
  {V; \Sp}{U}}
{\foctx{\Psi}{\Delta}{V}{[A^+]}
 &
 \foctx{\Psi}{\tackon{\Theta}{[B^-]}}{\Sp}{U}}
\]
\[
\infer[{\with}_{L1}]
{\foctx{\Psi}{\frameoff{\Theta}{[A_1^- \with A_2^-]}}
  {\pi_1; \Sp}{U}}
{\foctx{\Psi}{\tackon{\Theta}{[A_1^-]}}{\Sp}{U}}
\quad
\infer[{\with}_{L2}]
{\foctx{\Psi}{\frameoff{\Theta}{[A_1^- \with A_2^-]}}
  {\pi_2; \Sp}{U}}
{\foctx{\Psi}{\tackon{\Theta}{[A_2^-]}}{\Sp}{U}}
\]
\[
\infer[{\forall}_L]
{\foctx{\Psi}{\frameoff{\Theta}{[\forall \lf{a}{:}\tau. B^-]}}
  {\lf{t}; \Sp}{U}}
{\Psi \vdash_{\Sigma,\subord} \lf{t} : \tau
 &
 \foctx{\Psi}{\tackon{\Theta}{[(\lf{[t/a]}B^-)]}}{\Sp}{U}}
\]
\caption{\sls~deductive terms}
\label{fig:sls-deductive}
\end{figure}

\subsection{Deductive terms}
\label{sec:framework-deductive}

Deductive terms include values $V$, terms $N$, and spines $\Sp$ --
most of the core of the logic. 
\begin{align*}
V & ::= z
   \mid N
   \mid \tgnabr{N}
   \mid \tbangr{N}
   \mid \toner
   \mid \tfuser{V_1}{V_2}
   \mid \texistsr{\lf{t}}{V}
   \mid \tunifr
\\
N & ::= \tfocusl{x}{\Sp} 
   \mid \tfocusl{\sf r}{\Sp} 
   \mid \lambda P.N 
   \mid N_1 \with N_2
   \mid \tforallr{\lf{a}}{N}
   \ldots
\\
\Sp & ::= \tnil 
   \mid V; \Sp
   \mid \pi_1; \Sp 
   \mid \pi_2; \Sp
   \mid \lf{t}; \Sp
\end{align*}
The use of patterns removes many of the terms $N$ that appeard in
\ollll~proof terms. As with patterns, we appear to conflate the proof
terms associated with different proof rules -- we have a single
$\lambda P.N$ constructor and a single $V;\Sp$ spine rather than a
term $\tlamr{N}$ and spine $\tappr{V}{\Sp}$ associated with
propositions $A^+ \righti B^-$ and another term $\tlaml{N}$ and spine
$\tappl{V}{\Sp}$ associated with propositions $A^+ \lefti B^-$.  As
with patterns, it is possible to think of these terms as just having
extra annotations ($\lambda^>$ or $\lambda^<$) that we have omitted.
Without these annotations, proof terms carry less information than
derivations, and the rules for values, terms, and spines in
Figure~\ref{fig:sls-deductive} must be seen as typing rules. With
these extra implicit annotations, values, terms, and spines can
continue to be seen as representatives derivations.

The term typing inference rule labeled ${\sf rule}$ in
Figure~\ref{fig:sls-deductive} is the only typing rule for deductive
terms that does not have an exact analouge in \ollll. To perserve the
bijective correspondence between \ollll~and \sls~proof terms, we need
to either place every rule ${\sf r} : A^-$ in the \sls~signature
$\Sigma$ into the \ollll~context as a persistent proposition.

As with LF terms, we will write atomic terms $\tfocusl{x}{\Sp}$
and $\tfocusl{\sf r}{\Sp}$ in
shorthand, writing $({\sf foo}\,\lf{t}\,\lf{s}\,V\,V')$
instead of $\tfocusl{\sf foo}{(\lf{t};\lf{s};V;V';\tnil)}$ when we are
not concerned with the fact that the term is comprised of a variable
and a spine.

\begin{figure}
\fbox{$P :: (\Psi; \Delta)_{\lf{\sigma}} 
   \leadsto_{\Sigma,\subord}
  (\Psi'; \Delta')_{\lf{\sigma'}}$} -- presumes
  $\vdash_{\Sigma,\subord} (\Psi; \Delta)_{\lf{\sigma}}\,{\sf state}$
  and $\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf stable}$
\[
\infer
{\tstep{P}{x}{\Sp} :: 
  (\Psi; \frameoff{\Theta}{\frameoff{\Theta'}{x{:}A^-}})_{\lf{\sigma}} 
   \leadsto_{\Sigma,\subord}
  (\Psi'; \Delta')_{\lf{\sigma'}}}
{\foctx{\Psi}{\tackon{\Theta'}{[A^-]}}{\Sp}{\istrue{\susp{{\ocircle}{B^+}}}}
 &
 P :: (\Psi,\tackon{\Theta}{B^+})_{\lf{\sigma}}
   \Longrightarrow_{\Sigma,\subord}
      (\Psi'; \Delta')_{\lf{\sigma'}}}
\]
\[
\infer
{\tstep{P}{\sf r}{\Sp} :: 
  (\Psi; \frameoff{\Theta}{\frameoff{\Theta'}{\cdot}})_{\lf{\sigma}} 
   \leadsto_{\Sigma,\subord}
  (\Psi'; \Delta')_{\lf{\sigma'}}}
{{\sf r} : A^- \in \Sigma
 &
 \foctx{\Psi}{\tackon{\Theta'}{[A^-]}}{\Sp}{\istrue{\susp{{\ocircle}{B^+}}}}
 &
 P :: (\Psi,\tackon{\Theta}{B^+})_{\lf{\sigma}}
   \Longrightarrow_{\Sigma,\subord}
      (\Psi'; \Delta')_{\lf{\sigma'}}}
\]

\medskip
\fbox{$T :: (\Psi; \Delta)_{\lf{\sigma}} 
   \leadsto^*_{\Sigma,\subord}
  (\Psi'; \Delta')_{\lf{\sigma'}}$} -- presumes
  $\vdash_{\Sigma,\subord} (\Psi; \Delta)_{\lf{\sigma}}\,{\sf state}$
  and $\Psi \vdash_{\Sigma,\subord} \Delta\,{\sf stable}$
\[
\infer
{\emptytrace :: (\Psi; \Delta)_{\lf{\sigma}}}
{}
\quad
\infer
{S :: (\Psi; \Delta)_{\lf{\sigma}}
               \leadsto^*_{\Sigma,\subord}
             (\Psi'; \Delta')_{\lf{\sigma'}}}
{S :: (\Psi; \Delta)_{\lf{\sigma}}
               \leadsto_{\Sigma,\subord}
             (\Psi'; \Delta')_{\lf{\sigma'}}}
\]
\[
\infer
{T; T' :: (\Psi_1; \Delta_1)_{\lf{\sigma_1}}
               \leadsto^*_{\Sigma,\subord}
             (\Psi_3; \Delta_3)_{\lf{\sigma_3}}}
{T :: (\Psi_1; \Delta_1)_{\lf{\sigma_1}}
               \leadsto^*_{\Sigma,\subord}
             (\Psi_2; \Delta_2)_{\lf{\sigma_2}}
&
T' :: (\Psi_2; \Delta_2)_{\lf{\sigma_2}}
               \leadsto^*_{\Sigma,\subord}
             (\Psi_3; \Delta_3)_{\lf{\sigma_3}}}
\]
\caption{\sls~concurrent traces}
\label{fig:sls-concurrent}
\end{figure}

\subsection{Concurrent traces}
\label{sec:framework-concurrent}
\label{sec:framework-substprop}

Deductive traces and patterns handle every 
\sls~proposition except for the lax modaility ${\ocircle}A^+$. It is in 
the context of the lax modality that we will present proof terms 
corresponding to partial proofs. 
\begin{align*}
S & ::= \tstep{P}{x}{\Sp}
\\
T & ::= \emptytrace \mid T_1; T_2 \mid S
\end{align*}
A step $S = \tstep{P}{x}{\Sp}$ corresponds precisely to the notion of
a {\it synthetic inference rule} discussed in
Section~\ref{sec:linsynthetic}.  Whereas each typing rule for a
pattern, value, term, or spine corresponded to a rule in \ollll, a
step in \sls~corresponds to a use of left focus, a use of the
left rule for the lax modality, and a use of the 
admissible focal substitution lemma in \ollll:
\[
\infer-[{\it subst}^-]
{\foc{\Psi}{\frameoff{\Theta'}{\Delta}}{\islax{\lf{\sigma}A^+}}}
{\infer[{\it focus}_L]
 {\foc{\Psi}{\Delta}{\istrue{\susp{{\ocircle}B^+}}}}
 {\Delta\,{\it matches}\,\frameoff{\Theta'}{x{:}A^-}
  &
  \deduce
  {\foc{\Psi}{\tackon{\Theta'}{[A^-]}}{\istrue{\susp{{\ocircle}B^+}}}}
  {\vdots\mathstrut}}
 &
 \infer[{\ocircle}_L]
 {\foc{\Psi}{\tackon{\Theta}{[{\ocircle}B^+]}}{\islax{\lf{\sigma}A^+}}}
 {\deduce
  {\foc{\Psi}
    {\tackon{\Theta}{B^+}}
    {\islax{\lf{\sigma}A^+}}\mathstrut} 
  {\deduce{\vdots\mathstrut}
    {\vspace{-4pt}\foc{\Psi'}
     {\Delta'}
     {\islax{\lf{\sigma'}A^+}}}}}}
\]
The spine $\Sp$ corresponds to the complete proof of 
$\foc{\Psi}{\tackon{\Theta'}{[A^-]}}{\istrue{\susp{{\ocircle}B^+}}}$, and
the pattern $P$ corresponds to the partial proof of 
$\foc{\Psi}
    {\tackon{\Theta}{B^+}}
    {\islax{\lf{\sigma}A^+}}$. The typing rules for steps 
are given in Figure~\ref{fig:sls-concurrent}.

A step corresponds to a focusing 
stage (represented by $\Sp$)
%
followed by an inversion phase (represented by $P$), making it
a proof term for the {\it synthetic inference rules}
discussed in Section~\ref{sec:linsynthetic}. Because 
Because we understand these synthetic inference rules as relations
between process states, we can also call steps {\it synthetic
  transitions}. Traces $T$ are monoids over steps -- $\emptytrace$ is
an empty trace, $S$ is a trace consisting of a single step, and $T_1;
T_2$ is the sequential composition of traces. 

Steps incorporate left focus and the left rule for ${\ocircle}$, and
{\it let-expressions}, which allow concurrent traces can be included
into deductive terms, incorporate right focus and the right rule for
${\ocircle}$. Let expressions are an addition form of term, so we
extend the language of deductive terms with $N ::= \ldots \mid
\tlet{T}{V}$ associated with the right rule for equality.
\[
\infer[{\ocircle}_R]
{\foctx{\Psi}{\Delta}{\tlet{T}{V}}{{\ocircle}A^+}}
{T :: (\Psi; \Delta)_{\lf{\sf id}}
  \leadsto^*_{\Sigma,\subord}
 (\Psi';\Delta')_{\lf{\sigma'}}
 &
 \foctx{\Psi'}{\Delta'}{V}{[\lf{\sigma}A^+]}}
\]


\subsection{Concurrent equality}
\label{sec:linconcurrenteq}
\label{sec:framework-concurrenteq}

Concurrent equality is a notion of equivalence that operates on
traces, and represents an intermediate point between focusing and
multifocusing \cite{chaudhuri08canonical}.  Consider the following
\sls~signature:
\begin{align*}
 \Sigma = \cdot, 
~&{\sf a} : {\sf prop}\,{\sf ord},
~ {\sf b} : {\sf prop}\,{\sf ord},
~ {\sf c} : {\sf prop}\,{\sf ord},
~ {\sf d} : {\sf prop}\,{\sf ord},
~ {\sf e} : {\sf prop}\,{\sf ord},
~ {\sf f} : {\sf prop}\,{\sf ord},
\\ & 
  {\sf first}  : a^+ \lefti {\ocircle}(b^+ \fuse c^+), 
\\ &
  {\sf left}  : b^+ \lefti {\ocircle}d^+, ~
\\ &
  {\sf right} : c^+ \lefti {\ocircle}e^+, ~
\\ &
  {\sf last} : d^+ \fuse e^+ \lefti {\ocircle}f^+
\end{align*}
With the signature $\Sigma$ and a suitable subordination relation $\subord$, 
we can create two traces with the type
$x_a{:}\susp{\sf a} \leadsto^*_{\Sigma,\subord} x_f{:}\susp{\sf f}$:
\[
\begin{array}{rcl}
T_1 & = 
 & \trstep{x_b, x_c}{\sf first}\,x_a;\\
&& \trstep{x_d}{\sf left}\,x_b;\\
&& \trstep{x_e}{\sf right}\,x_c;\\
&& \trstep{x_f}{\sf last}\,(\tfuser{x_d}{x_e})
\end{array}
\quad
\mbox{versus}
\quad
\begin{array}{rcl}
T_2 & = 
 & \trstep{x_b, x_c}{\sf first}\,x_a;\\
&& \trstep{x_e}{\sf right}\,x_c;\\
&& \trstep{x_d}{\sf left}\,x_b;\\
&& \trstep{x_f}{\sf last}\,(\tfuser{x_d}{x_e})
\end{array}
\]
In both cases, there is an $x_a{:}\susp{\sf a}$ resource
that transitions to a $x_b{:}\susp{\sf b}$ resource and a
$x_c{:}\susp{\sf c}$ resource, and then $x_b{:}\susp{\sf b}$
transitions to $x_d{:}\susp{\sf d}$ while, independently,
$x_c{}\susp{\sf c}$ transitions to $x_d{:}\susp{\sf d}$. Then,
finally, the $x_d{:}\susp{\sf d}$ and $x_e{:}\susp{\sf e}$ combine to
transition to $x_f{:}\susp{\sf f}$, which completes the trace. 

The independence here is key: if two steps consume different
resources, then we want to treat them as independent concurrent steps
that could have equivalently happened in the other order. However, if
we define equvalence only in terms of the $\alpha$-equivalence of
\ollll~derivations, the two traces above are distinct. As a result, we
can introduce a corser equivalence relation, {\it concurrent
  equality}, that allows us to treat traces that differ only in the
interleaving of independent and concurrent steps as being equal.
Concurrent equality was first was introduced and explored in the
context of CLF \cite{watkins02concurrent}, but our presentation
follows the reformulation in \cite{cervesato12trace}, which defines
concurrent equivalence based on an analysis of the variables that 
are used, consumed, and introduced by each given step.

The {\it input variables} of a step $S = (\tstep{P}{x}{\Sp})$, denoted
${\bullet}S$, are intuitively the set of \lf~and \sls~variables free in
the step. The notion of what it means to be a free variable is fairly
well understood, but there is one unusual corner case in \sls. Our use
of unification, and the corresponding pattern $\lf{t/a}, P$, means
that \sls~patterns can contain free LF variables:
\begin{align*}
{\it FV}(()) & = \emptyset
\\
{\it FV}(\lf{a}, P) & = {\it FV}(P)/\{\lf{a}\} 
\\
{\it FV}(x, P) & = {\it FV}(P)
\\
{\it FV}(\lf{t/a}, P) & =  \{ \lf{a} \} \cup {\it FV}(P) \cup {\it FV}(\lf{t}) 
\end{align*}
Therefore, the input interface of a step ${\bullet}(\tstep{P}{x}{\Sp})
= \{ x \} \cup {\it FV}(P) \cup {\it FV}(\Sp)$.

The {\it consumed variables} of a step $S = (\tstep{P}{x}{\Sp})$,
denoted by ${\ast}S$, are the subset of the input variables that no
longer appear in the process state after a step. Every \sls~variable
in ${\bullet}S$ associated with a judgment $\istrue{T}$ or $\iseph{T}$
is a consumed variable. Any LF variable $\lf{a}$ that is subject to
unification $\lf{t/a}$ in the pattern $P$ is also a consumed variable
if $\lf{a}$ is a free variable of the pattern. If $\lf{a}$ is free in
$P$, then $\lf{t}$ must also be a variable $\lf{b}$, and if $\lf{b}$
is likewise free in $P$ it is included in the set of consumed
variables.

Finally, the {\it output variables} of a step $S = (\tstep{P}{x}{\Sp})$,
denoted by $S{\bullet}$, are all the variables $\lf{a}$ or $x$ bound by
the pattern $P$ that are not subsequently consumed by a unification
$\lf{t/a}$ in the same pattern. 

Consider a well-typed trace $S_1; S_2$ with two steps.  By renaming
bound variables in a trace, it is always possible to ensure that
variables bound by one step are distinct from variables used by that
step or any previous step -- that is, to ensure $\emptyset =
(S_1{\bullet} \cup S_2{\bullet}) \cap {\bullet}S_1 = {S_2}{\bullet}
\cap {\bullet}S_2$. If $S_1$ outputs some variable that $S_2$ takes as
input, then $S_2; S_1$ cannot be a well-typed trace. More subtly, if
$S_2$ consumes variables that $S_1$ uses, which can only happen in the
case of LF variables ``consumed'' by unification, then $S_2; S_1$ is
also not a well typed trace, though $S_2; \lf{\sigma}S_1$ could be
well typed for some substitution $\sigma$ that can be read off of the
pattern in step $S_1$. Conversely, if $S_1; S_2$ is well-typed,
$\emptyset = S_1{\bullet} \cap {\bullet}S_2$, and $\emptyset =
{\bullet}S_1 \cap {\ast}S_2 = {\ast}S_1 \cap {\bullet}S_2$, then $S_2;
S_1$ is also a well-typed trace.

Given a particular trace $T$, we can observe 

Having done so we can observe that $S_2; S_1$ is a
well-typed trace if and only if $S_1$ outputs no variables
that $S_2$ uses -- that is, that $S_1{\bullet} \cap {\bullet}S_2$.

are the same as variable
names in ${\bullet}S_1$ -- which is always possible by renaming of
bound variables --

bound by
a unification $\lf{t/a}$ as a consumed variable


 denoted ${\bullet}S$
are 

, is 
essentially the free variables of the trace, combined with any any. 


To define concurrent equality, we 

It is not obvious that our treatment of the interaction between 
unification and concurrent eqivalence is the right one. 

\section{Adequate encoding}

The lambda
calculus usually has application $e_1\,e_2$ (encoded in LF as ${\sf
  app}\,\interp{e_1}\,\interp{e_2}$) and abstraction $\lambda x.e$
(encoded in LF as ${\sf lam}\,\lambda x. \interp{e}$). 

\subsection{Adequacy for LF and deductive terms}

\subsection{Adequacy for concurrent traces}


\section{The \sls~implementation}
\label{sec:prototype}

The prototype implementation of \sls~contains 
Following CLF and the Celf implementation, we write ${\ocircle}A$ in
Celf as \verb|{A}|. The mobile modality ${\gnab}A$ doesn't have an
ASCII representation, so write \verb|$A| when $A$ is
mobile. Upshifts and downshifts are always inferred: this means that
we can't write down ${\uparrow}{\downarrow}A$ or
${\downarrow}{\uparrow}A$, but neither of these \ollll~propositions
are part of the \sls~fragment anyway.

Another change is for the sake of readability: if \verb|P| is a
positive atomic proposition, we can write \verb|!P| wherever \verb|P|
is expected. This allows us to write either \verb|a * b * c| or
\verb|a * $b * !c| in SLS to express the positive proposition ${\sf a}
\fuse {\sf b} \fuse {\sf c}$ where ${\sf a}$, ${\sf b}$, and ${\sf c}$
are ordered, linear, and persistent positive atomic propositions
(respectively).

\section{Logic programming interpretation}
\label{sec:framework-logicprog}

In Chapter 3 I call this distinction one between ``concurrent and deductive''
proofs, operationally it's the difference between forward chaining 
and backward chaining. Maintaining the distinction between these is why
we don't want the class $p^-_\mlax$ in the logic.

We have talked about {\it concurrent} and {\it deductive} proof
objects, and also about the intuitive notion of {\it concurrent
  computation} as the non-backtracking, forward-chaining 

(definitely discuss forward-chaining and backward-chaining as concepts)

Expand on literature review of quiescence from HOSC Section 4

Leave the question of quescense versus eagerly-trying-to-right-focus
versus saturation ambiguous. If you talk about pure saturation the
forward-reference Chapter 8. 

\subsection{Modes and well-moded specifications}
\label{sec:framework-modes}

\section{Design decisions}

\subsection{Pseudo-positive atoms}
\label{sec:pseudopositive}


\subsection{Why LF as a term language?}
\label{sec:why-not-fully-dependent}

The decision to use LF as a first-order domain of quantification
rather than using a fully-dependent system is based on several
considerations. First and foremost, this choice was sufficient for the
purposes of this thesis. In fact, for the purposes of this thesis, we
could used an even simpler term language of simply-typed LF
\cite{pfenning08church}; two other logic programming interpretations
of \sls-like frameworks, Lollimon \cite{lopez05monadic} and Ollibot
\cite{pfenning09substructural}, were based on simply-typed term
languages. Canonical LF and Spine Form LF are, at this point,
well-understood enough that the additional overhead of fully
dependently-typed terms is not a significant burden, and there are
examples beyond the scope of this thesis where term dependency is
useful.

On a theoretical level, it is a significant simplification when we
restrict ourselves to {\it any} typed term language with a reasonable
notion of equality and substitution. Spine Form LF and Canonical LF
are two examples; most conceivable simply-typed term languages would
also suffice. It is the thesis of this and the previous two chapters
that we can productively derive logical frameworks from focused
presentations of logic, but this simple is complicated when we apply it
to a dependent type theory like CLF that does not distinguish object
terms and proof terms. CLF terms have a notion of {\it concurrent
  equivalence} which is coarser the equivalence relation described by
focusing alone, and we want \sls~proof terms to have a similar notion
of equivalence. In this chapter we characterize concurrent equivalence
in Section~\ref{XXX}, after completing our discussion of the framework
and describing the proof term language.  In CLF, the framework's
definition relies on term equality, and equality of terms must take
concurrent equivalence into account, so concurrent equivalence of
(proof) terms is conceptually prior to the logic itself. We conjecture
that this complication is no great obstacle, but this thesis avoids
the issue.

On a practical level, there are advantages to using a well-understood
term language. The \sls~prototype implementation
(Section~\ref{sec:prototype}) uses the mature type reconstruction
engine of Twelf. Schack-Nielsen's implementation of type
reconstruction for Celf is complicated by the requirements of dealing
with a substructural term language, and the user is required to add
extra annotations to indicate persistent application and abstraction
\cite{schacknielsen08celf}. In \sls~(and in many CLF encodings) the
term language is intended to be persistent, so these extra annotations
just clutter specifications.

The restriction to a dependent type theory therefore does not come at
the cost of great expressive power. Conversely, it is by no means
clear that the addition of full CLF-like dependency comes with great
expressive benefit. Even in LF and Twelf, many interesting
specifications could be encoded in a two-level version of the
language: a simply-typed object term language and a dependently-typed
proof term language with first-order quantification over object
terms. This restriction is sufficient for settings such as Harper's
comprehensive survey of programming language design
\cite{harper12practical},\footnote{Harper's metatheory also extends LF
  by drawing a distinction between standard variables and nominal
  parameters, but this is an orthogonal point.} and it is built in to
the educational proof assistant SASyLF \cite{aldrich08sasylf}. In LF
and Twelf, the ability to use full dependent types is critical in part
because it allows us to express {\it metatheorems} -- theorems about
the programming languages and logics we have encoded, like progress
and preservation for a programming language or cut admissibility for a
logic. But in substructural logical frameworks like Linear LF, full
dependency has been found to be {\it insufficient} for expressing
metatheorems, which motivated the development of Hybrid LF as a
framework for writing metatheorems about LF \cite{reed09hybrid}. The
implementation of Hybrid LF effectively creates a stratification like
\sls's -- full LF as an object term language, a linear logical
framework with first-order quantification over object language terms,
and a hybrid language that can inspect both LF object terms and linear
proof terms. 

\begin{figure}[t]
\begin{align*}
\fbox{$\subst{\lf{t}}{\lf{\spi}}$}
\\
\subst{(\lf{\lambda x. t'})}{(\lf{t; \spi})}
 & = \subst{\rsubst{\lf{t}}{\lf{x}}{\lf{t'}}}{\lf{\spi}}
\\
\subst{\lfroot{\lf h}{\spi}}{\lfnil}
 & = \lfroot{\lf h}{\spi}
\end{align*}\begin{align*}
%\fbox{$[{\lf{t}}/{\lf{x}}]{\nu}$} &
%&
\fbox{$\rsubst{\lf{t}}{\lf{x}}{\lf{\spi}}$}&
&
\fbox{$\rsubst{\lf{t}}{\lf{x}}{\lf{t'}}$}&
&
\\
%[\lf{t}/\lf{x}](\lfpi{y}{\nu}{\nu'})
% & = \lfpi{y}{[\lf{t}/\lf{x}]\nu}{[\lf{t}/\lf{x}]\nu'} &
\rsubst{\lf t}{\lf x}{(\lf{t'; \spi})}
 & = \lf{\no{\rsubst{\lf t}{\lf x}{\lf{t'}}}; 
         \no{\rsubst{\lf t}{\lf x}{\lf{\spi}}}} &
\rsubst{\lf t}{\lf x}(\lf{\lambda y. t'})
 & = \lf{\lambda y.\, \no{\rsubst{\lf t}{\lf x}{\lf{t'}}}} 
      & (\lf x \neq \lf y) 
\\
\rsubst{\lf t}{\lf x}{\lfnil} 
 & = \lfnil &
\rsubst{\lf t}{\lf x}{(\lf{\lfroot{x}{\spi}})}
 & = \subst{\lf t}{\rsubst{\lf t}{\lf x}{\lf{\spi}}}
\\
& & 
\rsubst{\lf t}{\lf x}{(\lf{\lfroot{h}{\spi}})}
 & = \lfroot{\lf h}{\no{\rsubst{\lf t}{\lf x}{\lf{\spi}}}}
      & ({\it if}~ \lf{h} \neq \lf{x})
\end{align*}
\caption{Hereditary substitution on terms, spines, and classifiers}
\label{fig:lf-hsubst}
\end{figure}

\subsection{A logic of partial proofs}

While traces 

\subsection{Concurrent equality and multifocusing}

Concurrent equality gives rise to an equivalence relation on focused
derivations. This equivalence relation is related to the equivalence
relation induced by {\it multifocusing}
\cite{chaudhuri08canonical}. Multifocusing is a concept that has only
been carefully explored in classical linear logic; the central change
is that the rules which begins a focusing phase (in our presentation
of MELL there were three: ${\it focus_L}$, ${\it focus_R}$, and ${\it
  copy}$) are allowed to simultaneously pull other propositions into
focus.  As an illustration, if we reuse our notation from
Section~\ref{sec:linnote} we can present the following plausible
candidates for the multifocus rules in an intuitionistic system:
\[
\infer[{\it focus}_L]
{\mildseq{\Gamma}{\Delta / A_1^-, \ldots, A_n^- }{U}}
{n > 1
 &
 \mildseq{\Gamma}{\Delta, [A_1^-], \ldots, [A_n^-]}{U}}
\quad
\infer[{\it focus}_R]
{\mildseq{\Gamma}{\Delta / A_1^-, \ldots, A_n^-}{C^+}}
{n \geq 1
 &
 \mildseq{\Gamma}{\Delta, [A_1^-], \ldots, [A_n^-]}{[C^+]}}
\]
Multifocusing, however,
appears to provide an even coarser notion of equivalence on focused
proofs than concurrent equality does. In particular, the two
distinct focusing proofs below are not concurrently equal: the proof
on the right succeeds at proving $\langle c^- \rangle$ in one step,
but leaves a subgoal in which $b^+$ is proved indirectly, whereas the
proof at the right first transitions from having $\langle a^+ \rangle$
and $a^+ \lolli {\uparrow} b^+$ resources to having a $\langle b^+
\rangle$ resource, and only then proves $\langle c^- \rangle$, leaving
a subgoal in which $b^+$ is proved directly.
\[
\infer
{\mildseq{\cdot}
  {~~
   \langle a^+ \rangle, ~
   a^+ \lolli {\uparrow}b^+, ~
   {\downarrow}{\uparrow}b^+ \lolli c^-
   ~~}
  {~~\langle c^- \rangle}}
{\infer
{\mildseq{\cdot}
  {~~
   \langle a^+ \rangle, ~
   a^+ \lolli {\uparrow}b^+
   ~~}
  {b^+}}
{\infer
{\mildseq{\cdot}
  {~~
   \langle b^+ \rangle
   ~~}
  {b^+}}
{}}}
\deduce{\mathstrut}
{\deduce{\mathstrut}
{\mbox{\it vs.}\mathstrut}}
\infer
{\mildseq{\cdot}
  {~~
   \langle a^+ \rangle, ~
   a^+ \lolli {\uparrow}b^+, ~
   {\downarrow}{\uparrow}b^+ \lolli c^-
   ~~}
  {~~\langle c^- \rangle}}
{\infer
{\mildseq{\cdot}
  {~~
   \langle b^+ \rangle, ~
   {\downarrow}{\uparrow}b^+ \lolli c^-
   ~~}
  {~~\langle c^- \rangle}}
{\infer
{\mildseq{\cdot}
  {~~
   \langle b^+ \rangle
   ~~}
  {~~b^+}}
{}}}
\]
Despite the lack of a full account of intuitionistic multifocusing, we
can observe that the analogue of this sequent in classical linear
logic has only one multifocused proof, and it is reasonable to
conjecture that an account of multifocusing for intuitionistic logic
would also relate these proofs. In classical linear logic,
multifocusing offers a very fundamental normal form: any two proofs
that can be made equal by locally permuting inference rules have the
same multifocused proof.

CLF's restricted form of concurrent equality will be sufficient for
the logical framework in Chapter 4. In fact, for the fragment of the
the logic in Chapter 3 that comprises our logical framework in Chapter
4, I conjecture that concurrent equality and the equality given by
multifocusing coincide.\footnote{This obviously means that the example
  above will be outside the logical fragment that comprises the logical
  framework.}  This conjecture is obviously difficult to make precise,
much less prove, without a general theory of multifocusing in
intuitionistic logic.


\subsection{A warning about normalization}
\label{sec:warning}

In our earlier discussion of hereditary substitution and canonical
forms in Section~\ref{sec:linlogicalframeworks}, we mentioned that the
normalization theorem provided by hereditary substitution was weaker
than the so-called weak normalization theorem for LF. That is because
the weak normalization theorem says that any well-typed term can be
converted into a canonical ($\beta$-normal and $\eta$-long) term by a
particular series of $\beta$ and $\eta$ conversions. It is
self-evident, by this statement of the theorem, that the resulting
canonical term is equivalent to the original term.

On the other hand, when we use hereditary substitution in the obvious
way to obtain a Canonical LF term from an arbitrary non-canonical LF
term, we gain {\it no guarantees} about the relationship between the
non-canonical LF term and the Canonical LF term. The statement of the
theorem does not preclude taking a $\beta$-normal, $\eta$-long LF term
(like $\lambda x. \lambda y. x$ of type $p \rightarrow p \rightarrow
p$ for some atomic type $p$) into a structurally different Canonical
LF term (like $\lambda x. \lambda y. y$, which also has type $p
\rightarrow p \rightarrow p$). It is possible to gain such a guarantee
for LF, as Martens and Crary have shown in unpublished work
\cite{martens11mechanizing}, but this result is a non-trivial statement
about the constructive content of the normalization theorem. 

In our setting, we should be concerned that we might take a focused
proof, turn it into an unfocused proof by the obvious de-focalization
procedure (the constructive content of
Theorem~\ref{thm:linfocsound}), and then turn it back into a focused
proof by focalization (the constructive content of
Theorem~\ref{thm:linfoccomplete}) only to obtain a proof that was not
identical or even related. This is not at all a merely hypothetical
concern. We can run the mechanized structural focalization result from
\cite{simmons11structural} on a persistent proposition,
%
   $a^+ \supset 
   {\downarrow}(a^+ \supset {\uparrow}b^+) \supset
   {\downarrow}({\downarrow}{\uparrow}b^+ \supset c^-) \supset
   c^-$, 
%
which is similar to the example from
Section~\ref{sec:linconcurrenteq}.  In persistent logic (as in
linear logic) that proposition has two focused propositions that
are probably multifocusing equivalent (given a reasonable intuitionistic
notion of multifocusing) but that are not concurrently equivalent
under the proposed definition of concurrent equality. 
However, if we take the focused proof that focuses 
first on $a^+ \supset {\uparrow}b^+$, transform it into an unfocused 
proof, and then re-focus it, we will get the proof that focuses 
first on ${\downarrow}{\uparrow}b^+ \supset c^-$. Focalization,
in other words, is not a partial inverse of de-focalization in the structural
focalization development, except maybe modulo the (as yet undefined)
equivalence relation established by multifocusing. 

This example illustrates why we must be careful, but it is not a fatal
flaw for two reasons. The first reason is the aforementioned
conjecture that, for the restricted logical fragment defined in
Chapter 4 as the basis of our logical framework, the focalizations of
two proofs are concurrently equal if and only if the original proofs
are convertible by local permutations of rules, the same condition
that multifocusing satisfies. If this conjecture holds, it ought to be
the case that, modulo this coarser equivalence, focalization {\it is}
a partial inverse of de-focalization. Second, what is really at stake
here is our ability to write down non-normal proofs in a logical
framework that then normalizes them -- which is what the Twelf
implementation of LF and the Celf implementation of CLF do -- with the
confidence that we can look at a non-normal proof and know its
corresponding canonical form. In this thesis, we will be content to
work throughout with focused proofs and their analogues, so we can
afford to leave questions about convertability and weak normalization
to future work.

