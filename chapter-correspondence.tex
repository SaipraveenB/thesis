\chapter{On logical correspondence}

In Part 1, we defined \sls, the logical framework of substructural
logical specifications. For the purposes of this thesis, we are
primarily interested in using \sls~as a framework for specifying the
operational semantics of programming languages, especially stateful
and concurrent programming languages. This is not a new idea:
specifying the operational semantics of programming languages is one
of the examples used to illustrate the expressiveness of the original
CLF specifiacation \cite{cervesato02concurrent}, a specification style
that was later termed {\it substructural operational semantics} by
Pfenning \cite{pfenning04substructural}. The general idea of
representing the intermediate states of a computation as substructural
process states dates back to Miller \cite{miller92pi} and his
Ph.D. student Chirimar \cite{chirimar95proof}, who encoded the
intermediate states of a $\pi$-calculus and of a low-level RISC
machine (respectively) as contexts in focused classical linear logic.

However, \sls~has an extremely rich set of tools for specifying
concurrent computations, and we need to take some care not to end up
as victims of our own success. In order . The ; To make a
(carefully-chosen) analogy, various on-paper styles of specifying the
operational semantics are well-known and visually recongizable.  To
anyone literate in programming languages research, a quick glance
should be sufficent to observe that, for instance, the following two
rules give a natural (or big-step) semantics for the call-by-value
lambda calculus:
\[
\infer
{\lambda x. e \Downarrow \lambda x. e \mathstrut}
{}
\quad
\infer
{e_1\,e_2 \Downarrow v \mathstrut}
{e_1 \Downarrow \lambda x.e
 &
 e_2 \Downarrow v_2
 &
 [v_2/x]e \Downarrow v \mathstrut}
\]
Another form of semantics for programming languages, the {\it abstract
  machine} semantics, is slightly less canonical, but abstract machine
specifications nevertheless also have a set of common
conventions. There are two states in an abstract machine
specification, $k \rhd e$ (the expression $e$ is evaluating on top of
stack $k$) and $k \lhd v$ (the value $v$ is being returned to the top
of the stack $k$). The first rule says that, as a funtion $\lambda x.e$
is already a value, we proceed by returning it to the stack, whereas
for an application $e_1\,e_2$, 

\[
\infer
{k \rhd (\lambda x. e) ~\mapsto~ k \lhd (\lambda x. e) \mathstrut} 
{}
\quad
\infer
{k \rhd (e_1\,e_2) ~\mapsto~ (k; \Box\,e_2) \rhd e_1 \mathstrut}
{}
\]\[
\infer
{(k; \Box\,e_2) \lhd (\lambda x.e) ~\mapsto~ (k; (\lambda x.e)\Box) \rhd e_2
 \mathstrut}
{}
\quad
\infer
{(k; (\lambda x.e)\Box) \lhd v_2 ~\mapsto~ k \rhd [v_2/x]e
 \mathstrut}
{}
\]

There needs to be some structure and
at least


the design space
of 

 the general idea
of representing intermedeiate states of a computation as 
substructural process states 

This chapter represents joint work with Ian Zerny.

\section{Logical transformation: compilation}

Deductive computation versus concurrent computation 
Section~\ref{sec:framework-logicprog}

Deductive computation

\begin{figure}

%\fvset{fontsize=\small,boxwidth=229pt}
\fvset{fontsize=\small,boxwidth=187pt}
\BVerbatimInput{sls/cbv-ev.sls}
\fvset{fontsize=\small,boxwidth=auto}
\BVerbatimInput{sls/cbv-ev-ssos.sls}

\caption{A natural semantics for CBV and the corresponding abstract machine.}
\end{figure}

\subsection{Tail-recursion}

\subsection{Parallelism}

\section{Logical transformation: defunctionalization}

\section{Logical transformation: factoring}

Example: exceptions

\section{Exploring the richer fragment}

\subsection{Mutable storage}
\label{sec:mutable-storage}

No check for pointer inequality! This is a fundamental restriction of
the fact that we're using existential quantificaiton rather than some
form of nominal quantification. (Hack due to Favonia and Bob, personal
communication.)

\subsection{Call-by-need}

\subsection{Environment semantics}

\subsection{Looking back at natural semantics}
\label{sec:enriching-natsem}

\section{Partial transformation}


\subsection{Evaluation contexts}

Thus far, we have considered big-step operational semantics and abstract
machines, neglecting the third great tradition of programming language
specification, {\it structural operational semantics}. Structural
operational semantics (SOS) define single-step evaluation inductively over
the structure of expressions; the SOS semantics for our running example
language is the following:
\[
\infer
{\lambda x.e\,{\sf value} \mathstrut}
{}
\quad
\infer
{e_1\,e_2 \mapsto e_1'\,e_2 \mathstrut}
{e_1 \mapsto e_1' \mathstrut}
\quad
\infer
{e_1\,e_2 \mapsto e_1\,e_2' \mathstrut}
{e_1\,{\sf value}
 &
 e_2 \mapsto e_2' \mathstrut}
\quad
\infer
{(\lambda x. e)v \mapsto [v/x]e \mathstrut}
{v\,{\sf value} \mathstrut}
\]
This inductive specification is adequately encoded on the left-hand
side of Figure~\ref{fig:cbv-sos}, along with the proposition \Verb|ev|
that describes a big-step operational semantics in terms of repeated
application of the small-step operational semantics.

\begin{figure}[tp]
\fvset{fontsize=\small,boxwidth=229pt}
\BVerbatimInput{sls/cbv-sos.sls}
\BVerbatimInput{sls/cbv-sos-eval.sls}
\caption{Small-step evaluation, and one corresponding abstract machine.}
\label{fig:cbv-sos}
\end{figure}

\fvset{fontsize=\small}

There are a couple of possibilities for how the 
One obvious way to proceed is to simply translate the big-step portion
of our semantics as encoded 


If we just translate the {\it steps} portion of the semantics (using
the tail-recursion optimizing translation), then we will get what is
probabily fair to call the most boring possible substructural
operational semantics: 

\smallskip
\VerbatimInput{sls/cbv-sos-proc.sls}
\smallskip

\noindent
Under this semantics, the substructural context contains a single
resource, \Verb|eval-steps(E)|, which takes steps according to the
rules of the small-step structural operational semantics until a value
is reached, at which point the context contains \Verb|retn-steps(V)|.


\begin{figure}[t]
\VerbatimInput{sls/cbv-sos-defun.sls}
\caption{The defunctionalized abstract machine from Figure~\ref{fig:cbv-sos}.}
\label{fig:cbv-sos-defun}
\end{figure}

The interesting observations are to be had from the other direction: what if

\subsection{Temporal logic}

The natural semantics of \rowan~are not, on a superficial level,
significantly more complex than other natural semantics. However, it
turns out that the usual set of techniques for adding state to a
natural semantics break down, and discussing a \rowan-like logic with
state remained a challenge for many years.\robnote{Figure out from
  Rowan what the recent work he told you about was.} Through the
logical correspondance, it is easy to see why: the natural SSOS
specification of \rowan~integrates both concurrent and deductive
reasoning in an arbitrarily nested way. In fact, Figure XXX is the
only SLS specification in this thesis that exhibits this form of
recursive dependency between concurrent and deductive reasoning.  In
particular, the \rowan~specification is way out of the image of the
extended natural semantics we considered in
Section~\ref{sec:enriching-natsem}. The natural encoding in state lies
in the ambient substructural context of a concurrent computation, but
that ambient computation cannot properly enter into a deductive
sub-computation. If we tried to add state to \rowan~the same way we
added it in Section~\ref{sec:mutable-storage}, the entire store
would effectively leave scope whenever computation considered
the subterm $e$ of ${\sf next}(e)$. That consideration happens
as deductive reasoning, not as concurrent reasoning!

 it is the only we
will consider in this thesis that has with property.

It's hard to include state in temporal logic! But the logical correspondence
helps us understand why: the natural SSOS specification of 